{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentence-level-word-embeddings-with-ff",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rt247/Not_NLP_CW/blob/sentence-level-word-embeddings/sentence_level_word_embeddings_with_ff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6BshlcaZgmT",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Download datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzekR1EZY_5C",
        "colab_type": "code",
        "outputId": "828169e9-b4e1-4265-fdc4-d774ffcd9731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 20:47:18--  https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=39f30aabc3f4b3c50b4db6d373d3c4ccbad62150c90fd0e3d1e23c1c941cd8f6&X-Amz-Date=20200219T204718Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200219%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-19 20:47:19--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=39f30aabc3f4b3c50b4db6d373d3c4ccbad62150c90fd0e3d1e23c1c941cd8f6&X-Amz-Date=20200219T204718Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200219%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870893 (850K) [application/zip]\n",
            "Saving to: ‘enzh_data.zip’\n",
            "\n",
            "enzh_data.zip       100%[===================>] 850.48K  1.03MB/s    in 0.8s    \n",
            "\n",
            "2020-02-19 20:47:20 (1.03 MB/s) - ‘enzh_data.zip’ saved [870893/870893]\n",
            "\n",
            "Archive:  enzh_data.zip\n",
            "  inflating: dev.enzh.mt             \n",
            "  inflating: dev.enzh.scores         \n",
            "  inflating: dev.enzh.src            \n",
            "  inflating: test.enzh.mt            \n",
            "  inflating: test.enzh.src           \n",
            "  inflating: train.enzh.mt           \n",
            "  inflating: train.enzh.src          \n",
            "  inflating: train.enzh.scores       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UskRgN-6ZoKo",
        "colab_type": "text"
      },
      "source": [
        "Check data downloaded successfully:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQUZyQrXY_5a",
        "colab_type": "code",
        "outputId": "5b641d75-a189-4d5e-f5f8-d7f0672e5ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "with open(\"./train.enzh.src\", \"r\") as enzh_src:\n",
        "  print(\"Source: \",enzh_src.readline())\n",
        "with open(\"./train.enzh.mt\", \"r\") as enzh_mt:\n",
        "  print(\"Translation: \",enzh_mt.readline())\n",
        "with open(\"./train.enzh.scores\", \"r\") as enzh_scores:\n",
        "  print(\"Score: \",enzh_scores.readline())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source:  The last conquistador then rides on with his sword drawn.\n",
            "\n",
            "Translation:  最后的征服者骑着他的剑继续前进.\n",
            "\n",
            "Score:  -1.5284005772625449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV-JSE2sZzoT",
        "colab_type": "text"
      },
      "source": [
        "### English Models Setup\n",
        "\n",
        "Download English models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkP0aR4rZbVA",
        "colab_type": "code",
        "outputId": "c0fae716-5524-488b-f64e-d76e845d5042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 1.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=f17908a069b90da5980199c9e1207523c2215ee5f66f5a499b75f832eef21d52\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ze03tpr_/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYByRCqQaQDH",
        "colab_type": "text"
      },
      "source": [
        "Load a GloVe English model with dim 100.\n",
        "\n",
        "Some Chinese models only have **dim 100**, so we will need to **tokenize with spaCy, then embed with GloVe**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfblxyVaO3r",
        "colab_type": "code",
        "outputId": "ae5da993-4615-487e-843a-03cd6ddbf91c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torchtext\n",
        "import spacy\n",
        "\n",
        "# Embedding for English when dim 100\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "# Tokenizer for English when dim 100, Tokenizer and Embedding when dim 300\n",
        "nlp_en = spacy.load('en300')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.22MB/s]                           \n",
            "100%|█████████▉| 398452/400000 [00:31<00:00, 25209.71it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tWbs9PucbS0",
        "colab_type": "text"
      },
      "source": [
        "Functions for processing English dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoKMJIr5acPj",
        "colab_type": "code",
        "outputId": "143bf8e5-c72b-460b-f1c6-f4ae163da173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def preprocess_en(sentence, nlp):\n",
        "    text = sentence.lower()\n",
        "    doc = [token.lemma_ for token in  nlp.tokenizer(text)]\n",
        "    doc = [word for word in doc if word not in stop_words_en]\n",
        "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
        "    return doc\n",
        "\n",
        "def get_word_vector_en(embeddings, word):\n",
        "    try:\n",
        "      vec = embeddings.vectors[embeddings.stoi[word]]\n",
        "      return vec\n",
        "    except KeyError:\n",
        "      #print(f\"Word {word} does not exist\")\n",
        "      pass\n",
        "      \n",
        "\n",
        "def get_sentence_emb_en(line, nlp):\n",
        "  text = line.lower()\n",
        "  l = [token.lemma_ for token in nlp.tokenizer(text)]\n",
        "  l = ' '.join([word for word in l if word not in stop_words_en])\n",
        "\n",
        "  sen = nlp(l)\n",
        "  return sen.vector\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1930-s6fN7T",
        "colab_type": "text"
      },
      "source": [
        "### Chinese Models Setup\n",
        "\n",
        "Download Chinese stopwords:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O14b4JeHcNhB",
        "colab_type": "code",
        "outputId": "8c1d487f-7877-43b9-eee3-c68ee4dd7acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 20:55:32--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "chinese_stop_words.     [  <=>               ] 416.74K  1.59MB/s    in 0.3s    \n",
            "\n",
            "2020-02-19 20:55:33 (1.59 MB/s) - ‘chinese_stop_words.txt’ saved [426741]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw437fJCip68",
        "colab_type": "text"
      },
      "source": [
        "Download and load Chinese model with **dim 100** (University of Oslo):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8V-nUwUikda",
        "colab_type": "code",
        "outputId": "7b8d489b-adef-4601-863c-12626d8223e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "if not exists('zh_100.zip'):\n",
        "  !wget -O zh_100.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "  !unzip zh_100.zip -d ./zh_100\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_bin_100 = KeyedVectors.load_word2vec_format(\"./zh_100/model.bin\", binary=True) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 20:55:34--  http://vectors.nlpl.eu/repository/20/35.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458485917 (1.4G) [application/zip]\n",
            "Saving to: ‘zh_100.zip’\n",
            "\n",
            "zh_100.zip          100%[===================>]   1.36G  17.1MB/s    in 86s     \n",
            "\n",
            "2020-02-19 20:57:01 (16.2 MB/s) - ‘zh_100.zip’ saved [1458485917/1458485917]\n",
            "\n",
            "Archive:  zh_100.zip\n",
            "  inflating: ./zh_100/LIST           \n",
            "  inflating: ./zh_100/meta.json      \n",
            "  inflating: ./zh_100/model.bin      \n",
            "  inflating: ./zh_100/model.txt      \n",
            "  inflating: ./zh_100/README         \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo5vhydafzC5",
        "colab_type": "text"
      },
      "source": [
        "Functions for processing Chinese dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s27T7LXlf4sG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import jieba\n",
        "import gensim \n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "stop_words = [ line.rstrip() for line in open('./chinese_stop_words.txt',\"r\", encoding=\"utf-8\") ]\n",
        "\n",
        "def processing_zh(sentence):\n",
        "  seg_list = jieba.lcut(sentence,cut_all=True)\n",
        "  doc = [word for word in seg_list if word not in stop_words]\n",
        "  docs = [e for e in doc if e.isalnum()]\n",
        "  return docs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI0BAckemQOU",
        "colab_type": "text"
      },
      "source": [
        "## Process Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ6nLoxEmWN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "f_train_scores = open(\"./train.enzh.scores\", 'r')\n",
        "zh_train_scores = f_train_scores.readlines()\n",
        "\n",
        "f_val_scores = open(\"./dev.enzh.scores\", 'r')\n",
        "zh_val_scores = f_val_scores.readlines()\n",
        "\n",
        "train_scores = np.array(zh_train_scores).astype(float)\n",
        "y_train_zh = train_scores\n",
        "\n",
        "val_scores = np.array(zh_val_scores).astype(float)\n",
        "y_val_zh = val_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLV1j47Vo97i",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machines\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE4p089dsp1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF-AQtKJ4_p_",
        "colab_type": "text"
      },
      "source": [
        "### Using Average Word Embedding Vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpgfIUEhoOAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_avg_sentence_vector_zh(line, word_vectors):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    try:\n",
        "      emb = word_vectors[w]\n",
        "      vectors.append(emb)\n",
        "    except:\n",
        "      pass #Do not add if the word is out of vocabulary\n",
        "  if vectors:\n",
        "    return np.mean(vectors, axis=0).tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "def get_avg_embeddings_zh(f, word_vectors):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "  for l in lines:\n",
        "    sent  = processing_zh(l)\n",
        "    vec = get_avg_sentence_vector_zh(sent, word_vectors)\n",
        "\n",
        "    if vec is not None:\n",
        "      sentences_vectors.append(vec)\n",
        "    else:\n",
        "      print(l)\n",
        "  return sentences_vectors\n",
        "\n",
        "\n",
        "def get_avg_sentence_vector_en(embeddings, line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    emb = get_word_vector_en(embeddings, w)\n",
        "    #do not add if the word is out of vocabulary\n",
        "    if emb is not None:\n",
        "      vectors.append(emb)\n",
        "  if vectors:\n",
        "    return torch.mean(torch.stack(vectors), dim=0).tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "# assume dim 100\n",
        "def get_avg_embeddings_en(f, embeddings, nlp):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "    sentence = preprocess_en(l, nlp)\n",
        "    try:\n",
        "      vec = get_avg_sentence_vector_en(embeddings, sentence)\n",
        "      sentences_vectors.append(vec)\n",
        "    except:\n",
        "      sentences_vectors.append(0)\n",
        "\n",
        "  return sentences_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO1pLTEQpNya",
        "colab_type": "code",
        "outputId": "cc1893e9-e3cb-4729-bd8c-228b9b9d4e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "zh_train_mt_100_a = get_avg_embeddings_zh(\"./train.enzh.mt\", wv_from_bin_100)\n",
        "zh_train_src_100_a = get_avg_embeddings_en(\"./train.enzh.src\", glove, nlp_en)\n",
        "\n",
        "zh_val_mt_100_a = get_avg_embeddings_zh(\"./dev.enzh.mt\", wv_from_bin_100)\n",
        "zh_val_src_100_a = get_avg_embeddings_en(\"./dev.enzh.src\", glove, nlp_en)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.838 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJH3H9XqphpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_100_a = [x + y for x, y in zip(zh_train_src_100_a, zh_train_mt_100_a)]\n",
        "X_train_zh_100_a = np.array(X_train_100_a)\n",
        "\n",
        "X_val_100_a = [x + y for x, y in zip(zh_val_src_100_a, zh_val_mt_100_a)]\n",
        "X_val_zh_100_a = np.array(X_val_100_a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY1auosCuegb",
        "colab_type": "code",
        "outputId": "07d1b278-7227-426e-f936-2e1dca54a6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_a, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_a)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "linear\n",
        "RMSE: 0.9044962563186333 Pearson 0.3017781690203462\n",
        "\n",
        "poly\n",
        "RMSE: 0.8990697909416231 Pearson 0.3032902746054339\n",
        "\n",
        "rbf\n",
        "RMSE: 0.8900985622788053 Pearson 0.3403404558003603\n",
        "\n",
        "sigmoid\n",
        "RMSE: 7.152607007355879 Pearson -0.03977439348067312\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "RMSE: 0.9044962563186333 Pearson 0.3017781690203462\n",
            "\n",
            "poly\n",
            "RMSE: 0.8990697909416231 Pearson 0.3032902746054339\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8900985622788053 Pearson 0.3403404558003603\n",
            "\n",
            "sigmoid\n",
            "RMSE: 7.152607007355879 Pearson -0.03977439348067312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nHytkDwlz3z",
        "colab_type": "text"
      },
      "source": [
        "### Using Sum of Word Embedding Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_3IKDI-l2iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sum_sentence_vector_zh(line, word_vectors):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    try:\n",
        "      emb = word_vectors[w]\n",
        "      vectors.append(emb)\n",
        "    except:\n",
        "      pass #Do not add if the word is out of vocabulary\n",
        "  if vectors:\n",
        "    return np.sum(vectors, axis=0).tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "def get_sum_embeddings_zh(f, word_vectors):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "  for l in lines:\n",
        "    sent  = processing_zh(l)\n",
        "    vec = get_sum_sentence_vector_zh(sent, word_vectors)\n",
        "\n",
        "    if vec is not None:\n",
        "      sentences_vectors.append(vec)\n",
        "    else:\n",
        "      print(l)\n",
        "  return sentences_vectors\n",
        "\n",
        "\n",
        "def get_sum_sentence_vector_en(embeddings, line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    emb = get_word_vector_en(embeddings, w)\n",
        "    #do not add if the word is out of vocabulary\n",
        "    if emb is not None:\n",
        "      vectors.append(emb)\n",
        "  if vectors:\n",
        "    return torch.sum(torch.stack(vectors), dim=0).tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "# assume dim 100\n",
        "def get_sum_embeddings_en(f, embeddings, nlp):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "    sentence = preprocess_en(l, nlp)\n",
        "    try:\n",
        "      vec = get_sum_sentence_vector_en(embeddings, sentence)\n",
        "      sentences_vectors.append(vec)\n",
        "    except:\n",
        "      sentences_vectors.append(0)\n",
        "\n",
        "  return sentences_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6XZmLepmQxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zh_train_mt_100_s = get_sum_embeddings_zh(\"./train.enzh.mt\", wv_from_bin_100)\n",
        "zh_train_src_100_s = get_sum_embeddings_en(\"./train.enzh.src\", glove, nlp_en)\n",
        "\n",
        "zh_val_mt_100_s = get_sum_embeddings_zh(\"./dev.enzh.mt\", wv_from_bin_100)\n",
        "zh_val_src_100_s = get_sum_embeddings_en(\"./dev.enzh.src\", glove, nlp_en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Rn3RqfmYum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_100_s = [x + y for x, y in zip(zh_train_src_100_s, zh_train_mt_100_s)]\n",
        "X_train_zh_100_s = np.array(X_train_100_s)\n",
        "\n",
        "X_val_100_s = [x + y for x, y in zip(zh_val_src_100_s, zh_val_mt_100_s)]\n",
        "X_val_zh_100_s = np.array(X_val_100_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6PSaergmfjf",
        "colab_type": "code",
        "outputId": "9bed6654-ff0f-47b3-d96c-374354a54c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_s, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_s)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "linear\n",
        "RMSE: 0.9203004562821944 Pearson 0.2525785904226626\n",
        "\n",
        "poly\n",
        "RMSE: 0.9499024011434094 Pearson 0.18792023737965777\n",
        "\n",
        "rbf\n",
        "RMSE: 0.905470160037738 Pearson 0.29378234780721474\n",
        "\n",
        "sigmoid\n",
        "RMSE: 34.73144893811673 Pearson -0.004944951711832229\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "RMSE: 0.9203004562821944 Pearson 0.2525785904226626\n",
            "\n",
            "poly\n",
            "RMSE: 0.9499024011434094 Pearson 0.18792023737965777\n",
            "\n",
            "rbf\n",
            "RMSE: 0.905470160037738 Pearson 0.29378234780721474\n",
            "\n",
            "sigmoid\n",
            "RMSE: 34.73144893811673 Pearson -0.004944951711832229\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtlJk1Bz5jya",
        "colab_type": "text"
      },
      "source": [
        "### Using Min/Max of Word Embedding Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ALxvSE5vHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_min_sentence_vector_zh(line, word_vectors):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    try:\n",
        "      emb = word_vectors[w]\n",
        "      vectors.append(emb)\n",
        "    except:\n",
        "      pass #Do not add if the word is out of vocabulary\n",
        "  if vectors:\n",
        "    return np.amin(vectors, axis=0).tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "def get_min_embeddings_zh(f, word_vectors):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "  for l in lines:\n",
        "    sent  = processing_zh(l)\n",
        "    vec = get_min_sentence_vector_zh(sent, word_vectors)\n",
        "\n",
        "    if vec is not None:\n",
        "      sentences_vectors.append(vec)\n",
        "    else:\n",
        "      print(l)\n",
        "  return sentences_vectors\n",
        "\n",
        "\n",
        "def get_min_sentence_vector_en(embeddings, line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    emb = get_word_vector_en(embeddings, w)\n",
        "    #do not add if the word is out of vocabulary\n",
        "    if emb is not None:\n",
        "      vectors.append(emb)\n",
        "  if vectors:\n",
        "    return torch.min(torch.stack(vectors), dim=0)[0].tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "# assume dim 100\n",
        "def get_min_embeddings_en(f, embeddings, nlp):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "    sentence = preprocess_en(l, nlp)\n",
        "    try:\n",
        "      vec = get_min_sentence_vector_en(embeddings, sentence)\n",
        "      sentences_vectors.append(vec)\n",
        "    except:\n",
        "      sentences_vectors.append(0)\n",
        "\n",
        "  return sentences_vectors\n",
        "\n",
        "\n",
        "def get_max_sentence_vector_zh(line, word_vectors):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    try:\n",
        "      emb = word_vectors[w]\n",
        "      vectors.append(emb)\n",
        "    except:\n",
        "      pass #Do not add if the word is out of vocabulary\n",
        "  if vectors:\n",
        "    return np.amax(vectors, axis=0).tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "def get_max_embeddings_zh(f, word_vectors):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "  for l in lines:\n",
        "    sent  = processing_zh(l)\n",
        "    vec = get_max_sentence_vector_zh(sent, word_vectors)\n",
        "\n",
        "    if vec is not None:\n",
        "      sentences_vectors.append(vec)\n",
        "    else:\n",
        "      print(l)\n",
        "  return sentences_vectors\n",
        "\n",
        "\n",
        "def get_max_sentence_vector_en(embeddings, line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    emb = get_word_vector_en(embeddings, w)\n",
        "    #do not add if the word is out of vocabulary\n",
        "    if emb is not None:\n",
        "      vectors.append(emb)\n",
        "  if vectors:\n",
        "    return torch.max(torch.stack(vectors), dim=0)[0].tolist()\n",
        "  return [0] * 100\n",
        "\n",
        "# assume dim 100\n",
        "def get_max_embeddings_en(f, embeddings, nlp):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "    sentence = preprocess_en(l, nlp)\n",
        "    try:\n",
        "      vec = get_max_sentence_vector_en(embeddings, sentence)\n",
        "      sentences_vectors.append(vec)\n",
        "    except:\n",
        "      sentences_vectors.append(0)\n",
        "\n",
        "  return sentences_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDrkNPi97CP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zh_train_mt_100_min = get_min_embeddings_zh(\"./train.enzh.mt\", wv_from_bin_100)\n",
        "zh_train_src_100_min = get_min_embeddings_en(\"./train.enzh.src\", glove, nlp_en)\n",
        "zh_val_mt_100_min = get_min_embeddings_zh(\"./dev.enzh.mt\", wv_from_bin_100)\n",
        "zh_val_src_100_min = get_min_embeddings_en(\"./dev.enzh.src\", glove, nlp_en)\n",
        "\n",
        "zh_train_mt_100_max = get_max_embeddings_zh(\"./train.enzh.mt\", wv_from_bin_100)\n",
        "zh_train_src_100_max = get_max_embeddings_en(\"./train.enzh.src\", glove, nlp_en)\n",
        "zh_val_mt_100_max = get_max_embeddings_zh(\"./dev.enzh.mt\", wv_from_bin_100)\n",
        "zh_val_src_100_max = get_max_embeddings_en(\"./dev.enzh.src\", glove, nlp_en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUCHBHh57UhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "7f3f825f-0c59-4b17-fa0b-6f8d36968585"
      },
      "source": [
        "X_train_100_min = [x + y for x, y in zip(zh_train_src_100_min, zh_train_mt_100_min)]\n",
        "X_train_zh_100_min = np.array(X_train_100_min)\n",
        "X_val_100_min = [x + y for x, y in zip(zh_val_src_100_min, zh_val_mt_100_min)]\n",
        "X_val_zh_100_min = np.array(X_val_100_min)\n",
        "\n",
        "X_train_100_max = [x + y for x, y in zip(zh_train_src_100_max, zh_train_mt_100_max)]\n",
        "X_train_zh_100_max = np.array(X_train_100_max)\n",
        "X_val_100_max = [x + y for x, y in zip(zh_val_src_100_max, zh_val_mt_100_max)]\n",
        "X_val_zh_100_max = np.array(X_val_100_max)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
            "    close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC-LkWyjAv9n",
        "colab_type": "code",
        "outputId": "b2184626-caf9-4d8b-e088-c16e6b4397c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "print(\"min\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_min, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_min)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"max\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_max, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_max)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "min\n",
        "linear\n",
        "RMSE: 0.9174155670157896 Pearson 0.26925288419123733\n",
        "\n",
        "poly\n",
        "RMSE: 0.9721279726125316 Pearson 0.23475167649201809\n",
        "\n",
        "rbf\n",
        "RMSE: 0.9049414520907609 Pearson 0.2920329610610498\n",
        "\n",
        "sigmoid\n",
        "RMSE: 26.865545536417198 Pearson 0.0076818897644271664\n",
        "\n",
        "max\n",
        "linear\n",
        "RMSE: 0.9288259124772581 Pearson 0.2342204449314311\n",
        "\n",
        "poly\n",
        "RMSE: 1.0188986421056523 Pearson 0.18458085384794573\n",
        "\n",
        "rbf\n",
        "RMSE: 0.9074016100647716 Pearson 0.28092258260753544\n",
        "\n",
        "sigmoid\n",
        "RMSE: 26.529780761913454 Pearson -0.007926148030142141\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min\n",
            "linear\n",
            "RMSE: 0.9174155670157896 Pearson 0.26925288419123733\n",
            "\n",
            "poly\n",
            "RMSE: 0.9721279726125316 Pearson 0.23475167649201809\n",
            "\n",
            "rbf\n",
            "RMSE: 0.9049414520907609 Pearson 0.2920329610610498\n",
            "\n",
            "sigmoid\n",
            "RMSE: 26.865545536417198 Pearson 0.0076818897644271664\n",
            "\n",
            "max\n",
            "linear\n",
            "RMSE: 0.9288259124772581 Pearson 0.2342204449314311\n",
            "\n",
            "poly\n",
            "RMSE: 1.0188986421056523 Pearson 0.18458085384794573\n",
            "\n",
            "rbf\n",
            "RMSE: 0.9074016100647716 Pearson 0.28092258260753544\n",
            "\n",
            "sigmoid\n",
            "RMSE: 26.529780761913454 Pearson -0.007926148030142141\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qThYLeO7oJPB",
        "colab_type": "text"
      },
      "source": [
        "### Combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkpY7XYnoVr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# min + max\n",
        "X_train_100_mm = [sum(t, []) for t in zip(zh_train_src_100_min, zh_train_src_100_max, zh_train_mt_100_min, zh_train_mt_100_max)]\n",
        "X_train_zh_100_mm = np.array(X_train_100_mm)\n",
        "X_val_100_mm = [sum(t, []) for t in zip(zh_val_src_100_min, zh_val_src_100_max, zh_val_mt_100_min, zh_val_mt_100_max)]\n",
        "X_val_zh_100_mm = np.array(X_val_100_mm)\n",
        "\n",
        "# min + avg + max\n",
        "X_train_100_mam = [sum(t, []) for t in zip(zh_train_src_100_min, zh_train_src_100_a, zh_train_src_100_max, zh_train_mt_100_min, zh_train_mt_100_a, zh_train_mt_100_max)]\n",
        "X_train_zh_100_mam = np.array(X_train_100_mam)\n",
        "X_val_100_mam = [sum(t, []) for t in zip(zh_val_src_100_min, zh_val_src_100_a, zh_val_src_100_max, zh_val_mt_100_min, zh_val_mt_100_a, zh_val_mt_100_max)]\n",
        "X_val_zh_100_mam = np.array(X_val_100_mam)\n",
        "\n",
        "# avg + sum\n",
        "X_train_100_as = [sum(t, []) for t in zip(zh_train_src_100_a, zh_train_src_100_s, zh_train_mt_100_a, zh_train_mt_100_s)]\n",
        "X_train_zh_100_as = np.array(X_train_100_mam)\n",
        "X_val_100_as = [sum(t, []) for t in zip(zh_val_src_100_a, zh_val_src_100_s, zh_val_mt_100_a, zh_val_mt_100_s)]\n",
        "X_val_zh_100_as = np.array(X_val_100_mam)\n",
        "\n",
        "# min + avg + max + sum\n",
        "X_train_100_mams = [sum(t, []) for t in zip(zh_train_src_100_min, zh_train_src_100_a, zh_train_src_100_max, zh_train_src_100_s, zh_train_mt_100_min, zh_train_mt_100_a, zh_train_mt_100_max, zh_train_src_100_s)]\n",
        "X_train_zh_100_mams = np.array(X_train_100_mam)\n",
        "X_val_100_mams = [sum(t, []) for t in zip(zh_val_src_100_min, zh_val_src_100_a, zh_val_src_100_max, zh_val_src_100_s, zh_val_mt_100_min, zh_val_mt_100_a, zh_val_mt_100_max, zh_val_mt_100_s)]\n",
        "X_val_zh_100_mams = np.array(X_val_100_mam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMabHUiVo-o6",
        "colab_type": "code",
        "outputId": "76e897ea-dc70-49db-e701-7b0b608fa614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "source": [
        "print(\"min + max\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_mm, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_mm)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"min + avg + max\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_mam, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_mam)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"avg + sum\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_as, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_as)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"min + avg + max + sum\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_mams, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_mams)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "min + max\n",
        "linear\n",
        "RMSE: 0.9165262212864648 Pearson 0.26668369681069803\n",
        "\n",
        "poly\n",
        "RMSE: 0.9081786905379852 Pearson 0.3058041114768354\n",
        "\n",
        "rbf\n",
        "RMSE: 0.9084429289156349 Pearson 0.30464644770878846\n",
        "\n",
        "sigmoid\n",
        "RMSE: 3.5248833190245237 Pearson -0.006792767476776504\n",
        "\n",
        "min + avg + max\n",
        "linear\n",
        "RMSE: 0.9081244309157551 Pearson 0.28851234087420935\n",
        "\n",
        "poly\n",
        "RMSE: 0.8982943971746072 Pearson 0.3296975280939544\n",
        "\n",
        "rbf\n",
        "RMSE: 0.8992479975159785 Pearson 0.3292233306043897\n",
        "\n",
        "sigmoid\n",
        "RMSE: 2.600000956750181 Pearson 0.014142349847365135\n",
        "\n",
        "avg + sum\n",
        "linear\n",
        "RMSE: 0.9081244309157551 Pearson 0.28851234087420935\n",
        "\n",
        "poly\n",
        "RMSE: 0.8982943971746072 Pearson 0.3296975280939544\n",
        "\n",
        "rbf\n",
        "RMSE: 0.8992479975159785 Pearson 0.3292233306043897\n",
        "\n",
        "sigmoid\n",
        "RMSE: 2.600000956750181 Pearson 0.014142349847365135\n",
        "\n",
        "min + avg + max + sum\n",
        "linear\n",
        "RMSE: 0.9081244309157551 Pearson 0.28851234087420935\n",
        "\n",
        "poly\n",
        "RMSE: 0.8982943971746072 Pearson 0.3296975280939544\n",
        "\n",
        "rbf\n",
        "RMSE: 0.8992479975159785 Pearson 0.3292233306043897\n",
        "\n",
        "sigmoid\n",
        "RMSE: 2.600000956750181 Pearson 0.014142349847365135\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min + max\n",
            "linear\n",
            "RMSE: 0.9165262212864648 Pearson 0.26668369681069803\n",
            "\n",
            "poly\n",
            "RMSE: 0.9081786905379852 Pearson 0.3058041114768354\n",
            "\n",
            "rbf\n",
            "RMSE: 0.9084429289156349 Pearson 0.30464644770878846\n",
            "\n",
            "sigmoid\n",
            "RMSE: 3.5248833190245237 Pearson -0.006792767476776504\n",
            "\n",
            "min + avg + max\n",
            "linear\n",
            "RMSE: 0.9081244309157551 Pearson 0.28851234087420935\n",
            "\n",
            "poly\n",
            "RMSE: 0.8982943971746072 Pearson 0.3296975280939544\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8992479975159785 Pearson 0.3292233306043897\n",
            "\n",
            "sigmoid\n",
            "RMSE: 2.600000956750181 Pearson 0.014142349847365135\n",
            "\n",
            "avg + sum\n",
            "linear\n",
            "RMSE: 0.9081244309157551 Pearson 0.28851234087420935\n",
            "\n",
            "poly\n",
            "RMSE: 0.8982943971746072 Pearson 0.3296975280939544\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8992479975159785 Pearson 0.3292233306043897\n",
            "\n",
            "sigmoid\n",
            "RMSE: 2.600000956750181 Pearson 0.014142349847365135\n",
            "\n",
            "min + avg + max + sum\n",
            "linear\n",
            "RMSE: 0.9081244309157551 Pearson 0.28851234087420935\n",
            "\n",
            "poly\n",
            "RMSE: 0.8982943971746072 Pearson 0.3296975280939544\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8992479975159785 Pearson 0.3292233306043897\n",
            "\n",
            "sigmoid\n",
            "RMSE: 2.600000956750181 Pearson 0.014142349847365135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Lt3AWYxZ19",
        "colab_type": "text"
      },
      "source": [
        "## FFNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0Op0Q-gxl4D",
        "colab_type": "text"
      },
      "source": [
        "### Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sez0JE9NxoY-",
        "colab_type": "code",
        "outputId": "6ab7ed95-fd88-4049-d077-ac34ee16e083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import time\n",
        "import math\n",
        "\n",
        "###############\n",
        "# Torch setup #\n",
        "###############\n",
        "print('Torch version: {}, CUDA: {}'.format(torch.__version__, torch.version.cuda))\n",
        "cuda_available = torch.cuda.is_available()\n",
        "if not torch.cuda.is_available():\n",
        "  print('WARNING: You may want to change the runtime to GPU for Neural LM experiments!')\n",
        "  DEVICE = 'cpu'\n",
        "else:\n",
        "  DEVICE = 'cuda:0'\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version: 1.4.0, CUDA: 10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoVLrvbfUenV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "def ffln(train, valid, hidden_sizes=[64], batch_size=64, epochs=100, verbose=2, early_stop=True):\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  sizes = [train[0].size] + hidden_sizes\n",
        "  prev_s = None\n",
        "  layers = []\n",
        "  for s in sizes:\n",
        "    if prev_s:\n",
        "      layers.append(nn.Linear(prev_s, s).cuda())\n",
        "      layers.append(nn.LeakyReLU().cuda())\n",
        "    prev_s = s\n",
        "  layers.append(nn.Linear(prev_s, 1).cuda())\n",
        "\n",
        "  net = nn.Sequential(*layers)\n",
        "  \n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
        "  loss_func = nn.MSELoss()\n",
        "\n",
        "  net_X = Variable(torch.from_numpy(train))\n",
        "  net_y = Variable(torch.from_numpy(y_train_zh))\n",
        "  torch_dataset = Data.TensorDataset(net_X, net_y)\n",
        "  \n",
        "  loader = Data.DataLoader(\n",
        "      dataset=torch_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=2,\n",
        "  )\n",
        "  \n",
        "  net = net.float()\n",
        "\n",
        "  final_epoch = 0\n",
        "  last_pearson = None\n",
        "  for epoch in range(epochs):\n",
        "    training_loss = 0\n",
        "    for step, (batch_x, batch_y) in enumerate(loader):\n",
        "      b_x = Variable(batch_x.float().to(DEVICE))\n",
        "      b_y = Variable(batch_y.float().to(DEVICE))\n",
        "      prediction = torch.flatten(net(b_x))\n",
        "      loss = loss_func(prediction, b_y)\n",
        "      training_loss += mean_squared_error(b_y.cpu().detach().numpy(), prediction.cpu().detach().numpy())\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      training_loss = training_loss / step\n",
        "      with torch.no_grad():\n",
        "        net.eval()\n",
        "        net_val = Variable(torch.from_numpy(valid).float().to(DEVICE))\n",
        "        pred = torch.flatten(net.forward(net_val)).cpu().detach().numpy()\n",
        "        net.train()\n",
        "        pearson = pearsonr(y_val_zh, pred)\n",
        "        if last_pearson and early_stop and last_pearson > pearson[0]:\n",
        "          final_epoch = epoch\n",
        "          break\n",
        "        else:\n",
        "          last_pearson = pearson[0]\n",
        "        if verbose >= 2:\n",
        "          print(f\"Epoch {epoch} Training Loss: {training_loss}, Pearson Score: {pearson[0]}, MSE: {mean_squared_error(y_val_zh, pred)}\")\n",
        "    final_epoch = epoch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "    net_val = Variable(torch.from_numpy(valid).float().to(DEVICE))\n",
        "    pred = torch.flatten(net.forward(net_val)).cpu().detach().numpy()\n",
        "    net.train()\n",
        "    pearson = pearsonr(y_val_zh, pred)\n",
        "    if verbose >= 1:\n",
        "      print(f\"Final Validation Pearson Score: {pearson[0]}\")\n",
        "    return pearson[0], final_epoch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-K2s36ArCcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "44ded56f-634b-4e04-f3de-3935ba4e4851"
      },
      "source": [
        "hidden_sizes = [16, 32, 64, 128, 256]\n",
        "batch_sizes = [128, 256, 512, 1024, 2048]\n",
        "\n",
        "\n",
        "print(\"| Hidden Sizes | Batch Size | Final Epoch | Final Pearson Score |\")\n",
        "print(\"|---|---|---|---|\")\n",
        "for h in hidden_sizes:\n",
        "  for b in batch_sizes:\n",
        "    p, e = ffln(X_train_zh_100_a, X_val_zh_100_a, hidden_sizes=[h], batch_size=b, epochs=500, verbose=0)\n",
        "    print(f\"| {h} | {b} | {e} | {p} |\")\n",
        "\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Hidden Sizes | Batch Size | Final Epoch | Final Pearson Score |\n",
            "|---|---|---|---|\n",
            "| 16 | 128 | 110 | 0.3405388743143982 |\n",
            "| 16 | 256 | 170 | 0.3397500889705397 |\n",
            "| 16 | 512 | 240 | 0.3397802382015175 |\n",
            "| 16 | 1024 | 360 | 0.33749458056571224 |\n",
            "| 16 | 2048 | 450 | 0.33555132728957543 |\n",
            "| 32 | 128 | 150 | 0.35763019712700345 |\n",
            "| 32 | 256 | 200 | 0.35874265186421816 |\n",
            "| 32 | 512 | 280 | 0.3589732991591593 |\n",
            "| 32 | 1024 | 480 | 0.36208552479635675 |\n",
            "| 32 | 2048 | 480 | 0.35664063839674903 |\n",
            "| 64 | 128 | 110 | 0.3551239486036262 |\n",
            "| 64 | 256 | 150 | 0.35456388642073894 |\n",
            "| 64 | 512 | 200 | 0.35440647538707865 |\n",
            "| 64 | 1024 | 300 | 0.35546352390181984 |\n",
            "| 64 | 2048 | 340 | 0.3511669538054668 |\n",
            "| 128 | 128 | 80 | 0.35767577699197606 |\n",
            "| 128 | 256 | 100 | 0.358928734182707 |\n",
            "| 128 | 512 | 190 | 0.36029386571754496 |\n",
            "| 128 | 1024 | 260 | 0.3604532449340413 |\n",
            "| 128 | 2048 | 260 | 0.35858468110668523 |\n",
            "| 256 | 128 | 70 | 0.35963275593845023 |\n",
            "| 256 | 256 | 70 | 0.35865215871534833 |\n",
            "| 256 | 512 | 110 | 0.35839268431540866 |\n",
            "| 256 | 1024 | 210 | 0.3596300201177217 |\n",
            "| 256 | 2048 | 230 | 0.3589089199131525 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8p0Zw-jR_Xq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d9d2b08-c24e-493d-e2c9-92fed78cc53d"
      },
      "source": [
        "import itertools\n",
        "\n",
        "sizes = [8, 16, 32, 64, 128, 256]\n",
        "batch_sizes = [128, 256, 512, 1024]\n",
        "sizes = list(list(t) for t in itertools.product(sizes, sizes))\n",
        "search = list(itertools.product(sizes, batch_sizes))\n",
        "\n",
        "print(\"| Hidden Sizes | Batch Size | Final Epoch | Final Pearson Score |\")\n",
        "print(\"|---|---|---|---|\")\n",
        "for s, b in search:\n",
        "  p, e = ffln(X_train_zh_100_a, X_val_zh_100_a, hidden_sizes=s, batch_size=b, epochs=500, verbose=0)\n",
        "  print(f\"| {s} | {b} | {e} | {p} |\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Hidden Sizes | Batch Size | Final Epoch | Final Pearson Score |\n",
            "|---|---|---|---|\n",
            "| [8, 8] | 128 | 100 | 0.31607020961324017 |\n",
            "| [8, 8] | 256 | 190 | 0.325676763726344 |\n",
            "| [8, 8] | 512 | 300 | 0.3324969548357744 |\n",
            "| [8, 8] | 1024 | 360 | 0.3281781902107646 |\n",
            "| [8, 16] | 128 | 100 | 0.3209777141863661 |\n",
            "| [8, 16] | 256 | 130 | 0.3221153224067193 |\n",
            "| [8, 16] | 512 | 190 | 0.3231566499936152 |\n",
            "| [8, 16] | 1024 | 280 | 0.3230498553232637 |\n",
            "| [8, 32] | 128 | 120 | 0.3346557475599783 |\n",
            "| [8, 32] | 256 | 180 | 0.33722424679038093 |\n",
            "| [8, 32] | 512 | 260 | 0.3366840707272191 |\n",
            "| [8, 32] | 1024 | 380 | 0.33902853923076354 |\n",
            "| [8, 64] | 128 | 70 | 0.32322565055032326 |\n",
            "| [8, 64] | 256 | 100 | 0.32140369828739085 |\n",
            "| [8, 64] | 512 | 140 | 0.32344015250985336 |\n",
            "| [8, 64] | 1024 | 210 | 0.32310159143028583 |\n",
            "| [8, 128] | 128 | 110 | 0.32803432994968884 |\n",
            "| [8, 128] | 256 | 100 | 0.3225687835232611 |\n",
            "| [8, 128] | 512 | 150 | 0.324132143439027 |\n",
            "| [8, 128] | 1024 | 250 | 0.33223561787958855 |\n",
            "| [8, 256] | 128 | 70 | 0.32121855472735966 |\n",
            "| [8, 256] | 256 | 100 | 0.3237546131325545 |\n",
            "| [8, 256] | 512 | 140 | 0.3329252849480922 |\n",
            "| [8, 256] | 1024 | 210 | 0.3336608951953127 |\n",
            "| [16, 8] | 128 | 110 | 0.3338218750701204 |\n",
            "| [16, 8] | 256 | 160 | 0.33367430200846443 |\n",
            "| [16, 8] | 512 | 260 | 0.33783487037907806 |\n",
            "| [16, 8] | 1024 | 380 | 0.3343602634895123 |\n",
            "| [16, 16] | 128 | 90 | 0.32751355162369783 |\n",
            "| [16, 16] | 256 | 130 | 0.32544911716819336 |\n",
            "| [16, 16] | 512 | 180 | 0.32611950256584715 |\n",
            "| [16, 16] | 1024 | 300 | 0.3252353755969807 |\n",
            "| [16, 32] | 128 | 90 | 0.33678115996980906 |\n",
            "| [16, 32] | 256 | 120 | 0.33694877569799886 |\n",
            "| [16, 32] | 512 | 150 | 0.3379517207724726 |\n",
            "| [16, 32] | 1024 | 240 | 0.33864793192955467 |\n",
            "| [16, 64] | 128 | 90 | 0.33546713766353936 |\n",
            "| [16, 64] | 256 | 110 | 0.3351268630755747 |\n",
            "| [16, 64] | 512 | 170 | 0.334831960971154 |\n",
            "| [16, 64] | 1024 | 240 | 0.3345301173314305 |\n",
            "| [16, 128] | 128 | 50 | 0.32197850700097486 |\n",
            "| [16, 128] | 256 | 70 | 0.321114292249135 |\n",
            "| [16, 128] | 512 | 90 | 0.32243263757947094 |\n",
            "| [16, 128] | 1024 | 150 | 0.3231851621602055 |\n",
            "| [16, 256] | 128 | 50 | 0.3319655433287403 |\n",
            "| [16, 256] | 256 | 70 | 0.3318783247706317 |\n",
            "| [16, 256] | 512 | 100 | 0.32936809161762937 |\n",
            "| [16, 256] | 1024 | 150 | 0.3309949833319247 |\n",
            "| [32, 8] | 128 | 100 | 0.3545390609497202 |\n",
            "| [32, 8] | 256 | 160 | 0.35443749508226174 |\n",
            "| [32, 8] | 512 | 200 | 0.35279404732501746 |\n",
            "| [32, 8] | 1024 | 300 | 0.35189691560051056 |\n",
            "| [32, 16] | 128 | 80 | 0.3450570858370463 |\n",
            "| [32, 16] | 256 | 120 | 0.3470644324236091 |\n",
            "| [32, 16] | 512 | 150 | 0.34258651905040516 |\n",
            "| [32, 16] | 1024 | 250 | 0.3433293927002053 |\n",
            "| [32, 32] | 128 | 60 | 0.3461671087335401 |\n",
            "| [32, 32] | 256 | 80 | 0.3440974263749527 |\n",
            "| [32, 32] | 512 | 120 | 0.3445699352918116 |\n",
            "| [32, 32] | 1024 | 220 | 0.345383131162951 |\n",
            "| [32, 64] | 128 | 60 | 0.3502308183702131 |\n",
            "| [32, 64] | 256 | 80 | 0.34882030623007176 |\n",
            "| [32, 64] | 512 | 120 | 0.35037675287933817 |\n",
            "| [32, 64] | 1024 | 160 | 0.3508613704841181 |\n",
            "| [32, 128] | 128 | 40 | 0.34007629655976485 |\n",
            "| [32, 128] | 256 | 60 | 0.34000653142576936 |\n",
            "| [32, 128] | 512 | 90 | 0.3375105359908257 |\n",
            "| [32, 128] | 1024 | 130 | 0.33929379357353306 |\n",
            "| [32, 256] | 128 | 40 | 0.3462243601725155 |\n",
            "| [32, 256] | 256 | 60 | 0.3434485621830905 |\n",
            "| [32, 256] | 512 | 80 | 0.3450122144543767 |\n",
            "| [32, 256] | 1024 | 120 | 0.34611127468897557 |\n",
            "| [64, 8] | 128 | 80 | 0.33932535776382566 |\n",
            "| [64, 8] | 256 | 100 | 0.34147346129887296 |\n",
            "| [64, 8] | 512 | 140 | 0.3437998245201962 |\n",
            "| [64, 8] | 1024 | 220 | 0.34299150676415635 |\n",
            "| [64, 16] | 128 | 70 | 0.33874336234115937 |\n",
            "| [64, 16] | 256 | 90 | 0.3437671822812732 |\n",
            "| [64, 16] | 512 | 120 | 0.343263556245599 |\n",
            "| [64, 16] | 1024 | 190 | 0.33977573867193467 |\n",
            "| [64, 32] | 128 | 50 | 0.3442887197349294 |\n",
            "| [64, 32] | 256 | 60 | 0.3453337603357219 |\n",
            "| [64, 32] | 512 | 80 | 0.3474228567118349 |\n",
            "| [64, 32] | 1024 | 120 | 0.3446385026618806 |\n",
            "| [64, 64] | 128 | 50 | 0.34922983283257997 |\n",
            "| [64, 64] | 256 | 70 | 0.3517278731666611 |\n",
            "| [64, 64] | 512 | 90 | 0.3581329379744402 |\n",
            "| [64, 64] | 1024 | 130 | 0.3564654015874357 |\n",
            "| [64, 128] | 128 | 40 | 0.3360028177223755 |\n",
            "| [64, 128] | 256 | 50 | 0.34156212595622587 |\n",
            "| [64, 128] | 512 | 70 | 0.34200163122214994 |\n",
            "| [64, 128] | 1024 | 100 | 0.34459876433987324 |\n",
            "| [64, 256] | 128 | 40 | 0.34210065236058884 |\n",
            "| [64, 256] | 256 | 50 | 0.3458023122705053 |\n",
            "| [64, 256] | 512 | 70 | 0.3446082731532024 |\n",
            "| [64, 256] | 1024 | 100 | 0.3467760543524617 |\n",
            "| [128, 8] | 128 | 80 | 0.347945865626375 |\n",
            "| [128, 8] | 256 | 100 | 0.3446894641672712 |\n",
            "| [128, 8] | 512 | 140 | 0.3412687219325876 |\n",
            "| [128, 8] | 1024 | 210 | 0.34220621977988247 |\n",
            "| [128, 16] | 128 | 50 | 0.35183135764958157 |\n",
            "| [128, 16] | 256 | 70 | 0.35388721228149544 |\n",
            "| [128, 16] | 512 | 100 | 0.35624014377777374 |\n",
            "| [128, 16] | 1024 | 150 | 0.3534698964396123 |\n",
            "| [128, 32] | 128 | 50 | 0.33228526224288907 |\n",
            "| [128, 32] | 256 | 70 | 0.33563942459467067 |\n",
            "| [128, 32] | 512 | 90 | 0.3378259833179989 |\n",
            "| [128, 32] | 1024 | 130 | 0.3390340362227212 |\n",
            "| [128, 64] | 128 | 40 | 0.3405378288090267 |\n",
            "| [128, 64] | 256 | 50 | 0.3458943126862943 |\n",
            "| [128, 64] | 512 | 70 | 0.3477402042030332 |\n",
            "| [128, 64] | 1024 | 100 | 0.3494080282981141 |\n",
            "| [128, 128] | 128 | 30 | 0.3473700109493069 |\n",
            "| [128, 128] | 256 | 40 | 0.3490906563275689 |\n",
            "| [128, 128] | 512 | 60 | 0.34718029092073815 |\n",
            "| [128, 128] | 1024 | 80 | 0.35043725615687976 |\n",
            "| [128, 256] | 128 | 30 | 0.3284333649221471 |\n",
            "| [128, 256] | 256 | 40 | 0.3343714298023622 |\n",
            "| [128, 256] | 512 | 50 | 0.34002675577802416 |\n",
            "| [128, 256] | 1024 | 70 | 0.34164066750370364 |\n",
            "| [256, 8] | 128 | 50 | 0.35175351547264366 |\n",
            "| [256, 8] | 256 | 60 | 0.3535180692365392 |\n",
            "| [256, 8] | 512 | 90 | 0.3539472427754941 |\n",
            "| [256, 8] | 1024 | 130 | 0.35419315646426636 |\n",
            "| [256, 16] | 128 | 40 | 0.35841958055775397 |\n",
            "| [256, 16] | 256 | 60 | 0.36049100401781636 |\n",
            "| [256, 16] | 512 | 80 | 0.36290937059677664 |\n",
            "| [256, 16] | 1024 | 110 | 0.3618579321062537 |\n",
            "| [256, 32] | 128 | 40 | 0.3551907086727445 |\n",
            "| [256, 32] | 256 | 50 | 0.35375870065567455 |\n",
            "| [256, 32] | 512 | 70 | 0.3576068849944134 |\n",
            "| [256, 32] | 1024 | 100 | 0.36105843960104067 |\n",
            "| [256, 64] | 128 | 30 | 0.3537321580153696 |\n",
            "| [256, 64] | 256 | 40 | 0.35352727459453176 |\n",
            "| [256, 64] | 512 | 60 | 0.35321548914203643 |\n",
            "| [256, 64] | 1024 | 80 | 0.3569290871829409 |\n",
            "| [256, 128] | 128 | 30 | 0.3332589457261402 |\n",
            "| [256, 128] | 256 | 40 | 0.3419634143990482 |\n",
            "| [256, 128] | 512 | 50 | 0.3503789298387748 |\n",
            "| [256, 128] | 1024 | 70 | 0.3533004091096382 |\n",
            "| [256, 256] | 128 | 30 | 0.328592704747179 |\n",
            "| [256, 256] | 256 | 30 | 0.34040318926962315 |\n",
            "| [256, 256] | 512 | 40 | 0.34238660783044944 |\n",
            "| [256, 256] | 1024 | 60 | 0.3419457472489287 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCRV6Whlfcqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f04025ee-a804-4e2f-fca9-efa0ce51a213"
      },
      "source": [
        "ffln(X_train_zh_100_a, X_val_zh_100_a, hidden_sizes=[16], batch_size=256, epochs=500, verbose=0)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3397500889705397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqfV6RBbKLcI",
        "colab_type": "text"
      },
      "source": [
        "| Hidden Sizes | Batch Size | Final Epoch | Final Pearson Score |\n",
        "|---|---|---|---|\n",
        "| 16 | 128 | 110 | 0.3405388743143982 |\n",
        "| 16 | 256 | 170 | 0.3397500889705397 |\n",
        "| 16 | 512 | 240 | 0.3397802382015175 |\n",
        "| 16 | 1024 | 360 | 0.33749458056571224 |\n",
        "| 16 | 2048 | 450 | 0.33555132728957543 |\n",
        "| 32 | 128 | 150 | 0.35763019712700345 |\n",
        "| 32 | 256 | 200 | 0.35874265186421816 |\n",
        "| 32 | 512 | 280 | 0.3589732991591593 |\n",
        "| 32 | 1024 | 480 | **0.36208552479635675** |\n",
        "| 32 | 2048 | 480 | 0.35664063839674903 |\n",
        "| 64 | 128 | 110 | 0.3551239486036262 |\n",
        "| 64 | 256 | 150 | 0.35456388642073894 |\n",
        "| 64 | 512 | 200 | 0.35440647538707865 |\n",
        "| 64 | 1024 | 300 | 0.35546352390181984 |\n",
        "| 64 | 2048 | 340 | 0.3511669538054668 |\n",
        "| 128 | 128 | 80 | 0.35767577699197606 |\n",
        "| 128 | 256 | 100 | 0.358928734182707 |\n",
        "| 128 | 512 | 190 | 0.36029386571754496 |\n",
        "| 128 | 1024 | 260 | 0.3604532449340413 |\n",
        "| 128 | 2048 | 260 | 0.35858468110668523 |\n",
        "| 256 | 128 | 70 | 0.35963275593845023 |\n",
        "| 256 | 256 | 70 | 0.35865215871534833 |\n",
        "| 256 | 512 | 110 | 0.35839268431540866 |\n",
        "| 256 | 1024 | 210 | 0.3596300201177217 |\n",
        "| 256 | 2048 | 230 | 0.3589089199131525 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZyKqsndv7e",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Final Pearson Score |\n",
        "|---|---|---|---|\n",
        "| [8, 8] | 128 | 100 | 0.31607020961324017 |\n",
        "| [8, 8] | 256 | 190 | 0.325676763726344 |\n",
        "| [8, 8] | 512 | 300 | 0.3324969548357744 |\n",
        "| [8, 8] | 1024 | 360 | 0.3281781902107646 |\n",
        "| [8, 16] | 128 | 100 | 0.3209777141863661 |\n",
        "| [8, 16] | 256 | 130 | 0.3221153224067193 |\n",
        "| [8, 16] | 512 | 190 | 0.3231566499936152 |\n",
        "| [8, 16] | 1024 | 280 | 0.3230498553232637 |\n",
        "| [8, 32] | 128 | 120 | 0.3346557475599783 |\n",
        "| [8, 32] | 256 | 180 | 0.33722424679038093 |\n",
        "| [8, 32] | 512 | 260 | 0.3366840707272191 |\n",
        "| [8, 32] | 1024 | 380 | 0.33902853923076354 |\n",
        "| [8, 64] | 128 | 70 | 0.32322565055032326 |\n",
        "| [8, 64] | 256 | 100 | 0.32140369828739085 |\n",
        "| [8, 64] | 512 | 140 | 0.32344015250985336 |\n",
        "| [8, 64] | 1024 | 210 | 0.32310159143028583 |\n",
        "| [8, 128] | 128 | 110 | 0.32803432994968884 |\n",
        "| [8, 128] | 256 | 100 | 0.3225687835232611 |\n",
        "| [8, 128] | 512 | 150 | 0.324132143439027 |\n",
        "| [8, 128] | 1024 | 250 | 0.33223561787958855 |\n",
        "| [8, 256] | 128 | 70 | 0.32121855472735966 |\n",
        "| [8, 256] | 256 | 100 | 0.3237546131325545 |\n",
        "| [8, 256] | 512 | 140 | 0.3329252849480922 |\n",
        "| [8, 256] | 1024 | 210 | 0.3336608951953127 |\n",
        "| [16, 8] | 128 | 110 | 0.3338218750701204 |\n",
        "| [16, 8] | 256 | 160 | 0.33367430200846443 |\n",
        "| [16, 8] | 512 | 260 | 0.33783487037907806 |\n",
        "| [16, 8] | 1024 | 380 | 0.3343602634895123 |\n",
        "| [16, 16] | 128 | 90 | 0.32751355162369783 |\n",
        "| [16, 16] | 256 | 130 | 0.32544911716819336 |\n",
        "| [16, 16] | 512 | 180 | 0.32611950256584715 |\n",
        "| [16, 16] | 1024 | 300 | 0.3252353755969807 |\n",
        "| [16, 32] | 128 | 90 | 0.33678115996980906 |\n",
        "| [16, 32] | 256 | 120 | 0.33694877569799886 |\n",
        "| [16, 32] | 512 | 150 | 0.3379517207724726 |\n",
        "| [16, 32] | 1024 | 240 | 0.33864793192955467 |\n",
        "| [16, 64] | 128 | 90 | 0.33546713766353936 |\n",
        "| [16, 64] | 256 | 110 | 0.3351268630755747 |\n",
        "| [16, 64] | 512 | 170 | 0.334831960971154 |\n",
        "| [16, 64] | 1024 | 240 | 0.3345301173314305 |\n",
        "| [16, 128] | 128 | 50 | 0.32197850700097486 |\n",
        "| [16, 128] | 256 | 70 | 0.321114292249135 |\n",
        "| [16, 128] | 512 | 90 | 0.32243263757947094 |\n",
        "| [16, 128] | 1024 | 150 | 0.3231851621602055 |\n",
        "| [16, 256] | 128 | 50 | 0.3319655433287403 |\n",
        "| [16, 256] | 256 | 70 | 0.3318783247706317 |\n",
        "| [16, 256] | 512 | 100 | 0.32936809161762937 |\n",
        "| [16, 256] | 1024 | 150 | 0.3309949833319247 |\n",
        "| [32, 8] | 128 | 100 | 0.3545390609497202 |\n",
        "| [32, 8] | 256 | 160 | 0.35443749508226174 |\n",
        "| [32, 8] | 512 | 200 | 0.35279404732501746 |\n",
        "| [32, 8] | 1024 | 300 | 0.35189691560051056 |\n",
        "| [32, 16] | 128 | 80 | 0.3450570858370463 |\n",
        "| [32, 16] | 256 | 120 | 0.3470644324236091 |\n",
        "| [32, 16] | 512 | 150 | 0.34258651905040516 |\n",
        "| [32, 16] | 1024 | 250 | 0.3433293927002053 |\n",
        "| [32, 32] | 128 | 60 | 0.3461671087335401 |\n",
        "| [32, 32] | 256 | 80 | 0.3440974263749527 |\n",
        "| [32, 32] | 512 | 120 | 0.3445699352918116 |\n",
        "| [32, 32] | 1024 | 220 | 0.345383131162951 |\n",
        "| [32, 64] | 128 | 60 | 0.3502308183702131 |\n",
        "| [32, 64] | 256 | 80 | 0.34882030623007176 |\n",
        "| [32, 64] | 512 | 120 | 0.35037675287933817 |\n",
        "| [32, 64] | 1024 | 160 | 0.3508613704841181 |\n",
        "| [32, 128] | 128 | 40 | 0.34007629655976485 |\n",
        "| [32, 128] | 256 | 60 | 0.34000653142576936 |\n",
        "| [32, 128] | 512 | 90 | 0.3375105359908257 |\n",
        "| [32, 128] | 1024 | 130 | 0.33929379357353306 |\n",
        "| [32, 256] | 128 | 40 | 0.3462243601725155 |\n",
        "| [32, 256] | 256 | 60 | 0.3434485621830905 |\n",
        "| [32, 256] | 512 | 80 | 0.3450122144543767 |\n",
        "| [32, 256] | 1024 | 120 | 0.34611127468897557 |\n",
        "| [64, 8] | 128 | 80 | 0.33932535776382566 |\n",
        "| [64, 8] | 256 | 100 | 0.34147346129887296 |\n",
        "| [64, 8] | 512 | 140 | 0.3437998245201962 |\n",
        "| [64, 8] | 1024 | 220 | 0.34299150676415635 |\n",
        "| [64, 16] | 128 | 70 | 0.33874336234115937 |\n",
        "| [64, 16] | 256 | 90 | 0.3437671822812732 |\n",
        "| [64, 16] | 512 | 120 | 0.343263556245599 |\n",
        "| [64, 16] | 1024 | 190 | 0.33977573867193467 |\n",
        "| [64, 32] | 128 | 50 | 0.3442887197349294 |\n",
        "| [64, 32] | 256 | 60 | 0.3453337603357219 |\n",
        "| [64, 32] | 512 | 80 | 0.3474228567118349 |\n",
        "| [64, 32] | 1024 | 120 | 0.3446385026618806 |\n",
        "| [64, 64] | 128 | 50 | 0.34922983283257997 |\n",
        "| [64, 64] | 256 | 70 | 0.3517278731666611 |\n",
        "| [64, 64] | 512 | 90 | 0.3581329379744402 |\n",
        "| [64, 64] | 1024 | 130 | 0.3564654015874357 |\n",
        "| [64, 128] | 128 | 40 | 0.3360028177223755 |\n",
        "| [64, 128] | 256 | 50 | 0.34156212595622587 |\n",
        "| [64, 128] | 512 | 70 | 0.34200163122214994 |\n",
        "| [64, 128] | 1024 | 100 | 0.34459876433987324 |\n",
        "| [64, 256] | 128 | 40 | 0.34210065236058884 |\n",
        "| [64, 256] | 256 | 50 | 0.3458023122705053 |\n",
        "| [64, 256] | 512 | 70 | 0.3446082731532024 |\n",
        "| [64, 256] | 1024 | 100 | 0.3467760543524617 |\n",
        "| [128, 8] | 128 | 80 | 0.347945865626375 |\n",
        "| [128, 8] | 256 | 100 | 0.3446894641672712 |\n",
        "| [128, 8] | 512 | 140 | 0.3412687219325876 |\n",
        "| [128, 8] | 1024 | 210 | 0.34220621977988247 |\n",
        "| [128, 16] | 128 | 50 | 0.35183135764958157 |\n",
        "| [128, 16] | 256 | 70 | 0.35388721228149544 |\n",
        "| [128, 16] | 512 | 100 | 0.35624014377777374 |\n",
        "| [128, 16] | 1024 | 150 | 0.3534698964396123 |\n",
        "| [128, 32] | 128 | 50 | 0.33228526224288907 |\n",
        "| [128, 32] | 256 | 70 | 0.33563942459467067 |\n",
        "| [128, 32] | 512 | 90 | 0.3378259833179989 |\n",
        "| [128, 32] | 1024 | 130 | 0.3390340362227212 |\n",
        "| [128, 64] | 128 | 40 | 0.3405378288090267 |\n",
        "| [128, 64] | 256 | 50 | 0.3458943126862943 |\n",
        "| [128, 64] | 512 | 70 | 0.3477402042030332 |\n",
        "| [128, 64] | 1024 | 100 | 0.3494080282981141 |\n",
        "| [128, 128] | 128 | 30 | 0.3473700109493069 |\n",
        "| [128, 128] | 256 | 40 | 0.3490906563275689 |\n",
        "| [128, 128] | 512 | 60 | 0.34718029092073815 |\n",
        "| [128, 128] | 1024 | 80 | 0.35043725615687976 |\n",
        "| [128, 256] | 128 | 30 | 0.3284333649221471 |\n",
        "| [128, 256] | 256 | 40 | 0.3343714298023622 |\n",
        "| [128, 256] | 512 | 50 | 0.34002675577802416 |\n",
        "| [128, 256] | 1024 | 70 | 0.34164066750370364 |\n",
        "| [256, 8] | 128 | 50 | 0.35175351547264366 |\n",
        "| [256, 8] | 256 | 60 | 0.3535180692365392 |\n",
        "| [256, 8] | 512 | 90 | 0.3539472427754941 |\n",
        "| [256, 8] | 1024 | 130 | 0.35419315646426636 |\n",
        "| [256, 16] | 128 | 40 | 0.35841958055775397 |\n",
        "| [256, 16] | 256 | 60 | 0.36049100401781636 |\n",
        "| [256, 16] | 512 | 80 | 0.36290937059677664 |\n",
        "| [256, 16] | 1024 | 110 | 0.3618579321062537 |\n",
        "| [256, 32] | 128 | 40 | 0.3551907086727445 |\n",
        "| [256, 32] | 256 | 50 | 0.35375870065567455 |\n",
        "| [256, 32] | 512 | 70 | 0.3576068849944134 |\n",
        "| [256, 32] | 1024 | 100 | 0.36105843960104067 |\n",
        "| [256, 64] | 128 | 30 | 0.3537321580153696 |\n",
        "| [256, 64] | 256 | 40 | 0.35352727459453176 |\n",
        "| [256, 64] | 512 | 60 | 0.35321548914203643 |\n",
        "| [256, 64] | 1024 | 80 | 0.3569290871829409 |\n",
        "| [256, 128] | 128 | 30 | 0.3332589457261402 |\n",
        "| [256, 128] | 256 | 40 | 0.3419634143990482 |\n",
        "| [256, 128] | 512 | 50 | 0.3503789298387748 |\n",
        "| [256, 128] | 1024 | 70 | 0.3533004091096382 |\n",
        "| [256, 256] | 128 | 30 | 0.328592704747179 |\n",
        "| [256, 256] | 256 | 30 | 0.34040318926962315 |\n",
        "| [256, 256] | 512 | 40 | 0.34238660783044944 |\n",
        "| [256, 256] | 1024 | 60 | 0.3419457472489287 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_eVxCFdo8kJ",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "(Haven't tested the function yet...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XimIq82so7Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def writeScores(scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")\n",
        "\n",
        "\n",
        "def downloadScores(method_name, scores):\n",
        "  writeScores(scores)\n",
        "  with ZipFile(f\"en-zh_{method_name}.zip\", \"w\") as newzip:\n",
        "    newzip.write(\"predictions.txt\")\n",
        "  \n",
        "  files.download(f\"en-zh_{method_name}.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "471QN-wLp1ER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}