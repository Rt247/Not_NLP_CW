{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentence-level-word-embeddings-with-ff",
      "provenance": [],
      "collapsed_sections": [
        "hMmUggkzQjiT"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rt247/Not_NLP_CW/blob/sentence-level-word-embeddings/sentence_level_word_embeddings_with_ff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6BshlcaZgmT",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Download datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzekR1EZY_5C",
        "colab_type": "code",
        "outputId": "302d0b5e-1760-4186-d8c2-97c73d54935c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-25 19:42:12--  https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d08c8c6d890c740ad0656172d1a2e0fc713a2e187ed964709a91a20e20d92c96&X-Amz-Date=20200225T194217Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200225%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-25 19:42:18--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d08c8c6d890c740ad0656172d1a2e0fc713a2e187ed964709a91a20e20d92c96&X-Amz-Date=20200225T194217Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200225%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870893 (850K) [application/zip]\n",
            "Saving to: ‘enzh_data.zip’\n",
            "\n",
            "enzh_data.zip       100%[===================>] 850.48K  1.02MB/s    in 0.8s    \n",
            "\n",
            "2020-02-25 19:42:20 (1.02 MB/s) - ‘enzh_data.zip’ saved [870893/870893]\n",
            "\n",
            "Archive:  enzh_data.zip\n",
            "  inflating: dev.enzh.mt             \n",
            "  inflating: dev.enzh.scores         \n",
            "  inflating: dev.enzh.src            \n",
            "  inflating: test.enzh.mt            \n",
            "  inflating: test.enzh.src           \n",
            "  inflating: train.enzh.mt           \n",
            "  inflating: train.enzh.src          \n",
            "  inflating: train.enzh.scores       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UskRgN-6ZoKo",
        "colab_type": "text"
      },
      "source": [
        "Check data downloaded successfully:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQUZyQrXY_5a",
        "colab_type": "code",
        "outputId": "8a4ed352-2502-4eca-b070-d0adba5b7018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "with open(\"./train.enzh.src\", \"r\") as enzh_src:\n",
        "  print(\"Source: \",enzh_src.readline())\n",
        "with open(\"./train.enzh.mt\", \"r\") as enzh_mt:\n",
        "  print(\"Translation: \",enzh_mt.readline())\n",
        "with open(\"./train.enzh.scores\", \"r\") as enzh_scores:\n",
        "  print(\"Score: \",enzh_scores.readline())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source:  The last conquistador then rides on with his sword drawn.\n",
            "\n",
            "Translation:  最后的征服者骑着他的剑继续前进.\n",
            "\n",
            "Score:  -1.5284005772625449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV-JSE2sZzoT",
        "colab_type": "text"
      },
      "source": [
        "### English Models Setup\n",
        "\n",
        "Download English models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkP0aR4rZbVA",
        "colab_type": "code",
        "outputId": "02d325a4-d153-492f-b870-e17470af9082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 5.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=b9271e98eb9cb4e3cf2c32d0a6fc22ecc5f6fbb169bf0b728be2e4b85e8217c8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9c2rqkog/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYByRCqQaQDH",
        "colab_type": "text"
      },
      "source": [
        "Load a GloVe English model with dim 100.\n",
        "\n",
        "Some Chinese models only have **dim 100**, so we will need to **tokenize with spaCy, then embed with GloVe**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfblxyVaO3r",
        "colab_type": "code",
        "outputId": "54904dfb-b739-4715-8f9f-cf99b3de8a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torchtext\n",
        "import spacy\n",
        "\n",
        "# Embedding for English when dim 100\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "# Tokenizer for English when dim 100, Tokenizer and Embedding when dim 300\n",
        "nlp_en = spacy.load('en300')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:39, 2.16MB/s]                           \n",
            " 99%|█████████▉| 397721/400000 [00:31<00:00, 23835.67it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tWbs9PucbS0",
        "colab_type": "text"
      },
      "source": [
        "Functions for processing English dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoKMJIr5acPj",
        "colab_type": "code",
        "outputId": "a01aafd9-9585-4adc-9ba9-ab537b46781b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def preprocess_en(sentence, nlp):\n",
        "    text = sentence.lower()\n",
        "    doc = [token.lemma_ for token in  nlp.tokenizer(text)]\n",
        "    doc = [word for word in doc if word not in stop_words_en]\n",
        "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
        "    return doc\n",
        "\n",
        "def get_word_vector_en(embeddings, word):\n",
        "    try:\n",
        "      vec = embeddings.vectors[embeddings.stoi[word]]\n",
        "      return vec\n",
        "    except KeyError:\n",
        "      #print(f\"Word {word} does not exist\")\n",
        "      pass\n",
        "      \n",
        "\n",
        "def get_sentence_emb_en(line, nlp):\n",
        "  text = line.lower()\n",
        "  l = [token.lemma_ for token in nlp.tokenizer(text)]\n",
        "  l = ' '.join([word for word in l if word not in stop_words_en])\n",
        "\n",
        "  sen = nlp(l)\n",
        "  return sen.vector\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1930-s6fN7T",
        "colab_type": "text"
      },
      "source": [
        "### Chinese Models Setup\n",
        "\n",
        "Download Chinese stopwords:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O14b4JeHcNhB",
        "colab_type": "code",
        "outputId": "9f4a7c7a-65a1-46a3-b84f-16b2353c152c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-25 19:50:39--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "chinese_stop_words.     [ <=>                ] 417.14K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-02-25 19:50:40 (3.21 MB/s) - ‘chinese_stop_words.txt’ saved [427150]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw437fJCip68",
        "colab_type": "text"
      },
      "source": [
        "Download and load Chinese model with **dim 100** (University of Oslo):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8V-nUwUikda",
        "colab_type": "code",
        "outputId": "d826d218-fb27-45c6-ea65-2728419f0d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "if not exists('zh_100.zip'):\n",
        "  !wget -O zh_100.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "  !unzip zh_100.zip -d ./zh_100\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_bin_100 = KeyedVectors.load_word2vec_format(\"./zh_100/model.bin\", binary=True) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-25 19:50:41--  http://vectors.nlpl.eu/repository/20/35.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458485917 (1.4G) [application/zip]\n",
            "Saving to: ‘zh_100.zip’\n",
            "\n",
            "zh_100.zip          100%[===================>]   1.36G  16.7MB/s    in 87s     \n",
            "\n",
            "2020-02-25 19:52:10 (15.9 MB/s) - ‘zh_100.zip’ saved [1458485917/1458485917]\n",
            "\n",
            "Archive:  zh_100.zip\n",
            "  inflating: ./zh_100/LIST           \n",
            "  inflating: ./zh_100/meta.json      \n",
            "  inflating: ./zh_100/model.bin      \n",
            "  inflating: ./zh_100/model.txt      \n",
            "  inflating: ./zh_100/README         \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo5vhydafzC5",
        "colab_type": "text"
      },
      "source": [
        "Functions for processing Chinese dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s27T7LXlf4sG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import jieba\n",
        "import gensim \n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "stop_words = [ line.rstrip() for line in open('./chinese_stop_words.txt',\"r\", encoding=\"utf-8\") ]\n",
        "\n",
        "def preprocess_zh(sentence):\n",
        "  seg_list = jieba.lcut(sentence,cut_all=True)\n",
        "  doc = [word for word in seg_list if word not in stop_words]\n",
        "  docs = [e for e in doc if e.isalpha()]\n",
        "  return docs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI0BAckemQOU",
        "colab_type": "text"
      },
      "source": [
        "## Process Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ6nLoxEmWN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "f_train_scores = open(\"./train.enzh.scores\", 'r')\n",
        "zh_train_scores = f_train_scores.readlines()\n",
        "\n",
        "f_val_scores = open(\"./dev.enzh.scores\", 'r')\n",
        "zh_val_scores = f_val_scores.readlines()\n",
        "\n",
        "train_scores = np.array(zh_train_scores).astype(float)\n",
        "y_train_zh = train_scores\n",
        "\n",
        "val_scores = np.array(zh_val_scores).astype(float)\n",
        "y_val_zh = val_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2jJU-BKFl_b",
        "colab_type": "text"
      },
      "source": [
        "## Word Embedding Variants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh8Oi0IKGx3A",
        "colab_type": "text"
      },
      "source": [
        "Calculating various values as an aggregation of a sentence's word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHBctKt54DgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings_zh(f, word_vectors):\n",
        "  file = open(f)\n",
        "  lines = file.readlines()\n",
        "  embeddings = []\n",
        "  for l in lines:\n",
        "    sent = preprocess_zh(l)\n",
        "    embeddings_sent = []\n",
        "    for w in sent:\n",
        "      try:\n",
        "        emb = word_vectors[w]\n",
        "        embeddings_sent.append(emb)\n",
        "      except:\n",
        "        pass\n",
        "    if not embeddings_sent:\n",
        "      embeddings_sent = [[0] * 100]\n",
        "    embeddings.append(np.array(embeddings_sent))\n",
        "  return embeddings\n",
        "\n",
        "def get_embeddings_en(f, word_vectors, nlp):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  embeddings = []\n",
        "  for l in lines:\n",
        "    sent = preprocess_en(l, nlp)\n",
        "    embeddings_sent = []\n",
        "    for w in sent:\n",
        "      emb = get_word_vector_en(word_vectors, w)\n",
        "      if emb is not None:\n",
        "        embeddings_sent.append(emb.numpy())\n",
        "    if not embeddings_sent:\n",
        "      embeddings_sent = [[0] * 100]\n",
        "    embeddings.append(np.array(embeddings_sent))\n",
        "  return embeddings\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNMpJ_2d5syp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zh_train_mt_100_emb = get_embeddings_zh(\"./train.enzh.mt\", wv_from_bin_100)\n",
        "zh_train_src_100_emb = get_embeddings_en(\"./train.enzh.src\", glove, nlp_en)\n",
        "\n",
        "zh_val_mt_100_emb = get_embeddings_zh(\"./dev.enzh.mt\", wv_from_bin_100)\n",
        "zh_val_src_100_emb = get_embeddings_en(\"./dev.enzh.src\", glove, nlp_en)\n",
        "\n",
        "zh_test_mt_100_emb = get_embeddings_zh(\"./test.enzh.mt\", wv_from_bin_100)\n",
        "zh_test_src_100_emb = get_embeddings_en(\"./test.enzh.src\", glove, nlp_en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q7xwQL8Fpc4",
        "colab_type": "text"
      },
      "source": [
        "### Average Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpgfIUEhoOAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_word_embeddings(src, mt):\n",
        "  src_m = np.array([np.mean(e, axis=0) for e in src])\n",
        "  mt_m = np.array([np.mean(e, axis=0) for e in mt])\n",
        "  return np.concatenate((src_m, mt_m), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJH3H9XqphpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_zh_100_a = average_word_embeddings(zh_train_src_100_emb, zh_train_mt_100_emb)\n",
        "X_val_zh_100_a = average_word_embeddings(zh_val_src_100_emb, zh_val_mt_100_emb)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyXjHZNUF-M-",
        "colab_type": "text"
      },
      "source": [
        "### Sum Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pY_cSwgFPf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum_word_embeddings(src, mt):\n",
        "  src_m = np.array([np.sum(e, axis=0) for e in src])\n",
        "  mt_m = np.array([np.sum(e, axis=0) for e in mt])\n",
        "  return np.concatenate((src_m, mt_m), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Rn3RqfmYum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_zh_100_s = sum_word_embeddings(zh_train_src_100_emb, zh_train_mt_100_emb)\n",
        "X_val_zh_100_s = sum_word_embeddings(zh_val_src_100_emb, zh_val_mt_100_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQlWvJcGF_rs",
        "colab_type": "text"
      },
      "source": [
        "### Min/Max Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiLu9eSwIElW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def min_word_embeddings(src, mt):\n",
        "  src_m = np.array([np.amin(e, axis=0) for e in src])\n",
        "  mt_m = np.array([np.amin(e, axis=0) for e in mt])\n",
        "  return np.concatenate((src_m, mt_m), axis=1)\n",
        "\n",
        "def max_word_embeddings(src, mt):\n",
        "  src_m = np.array([np.amax(e, axis=0) for e in src])\n",
        "  mt_m = np.array([np.amax(e, axis=0) for e in mt])\n",
        "  return np.concatenate((src_m, mt_m), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUCHBHh57UhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_zh_100_min = min_word_embeddings(zh_train_src_100_emb, zh_train_mt_100_emb)\n",
        "X_val_zh_100_min = min_word_embeddings(zh_val_src_100_emb, zh_val_mt_100_emb)\n",
        "\n",
        "X_train_zh_100_max = max_word_embeddings(zh_train_src_100_emb, zh_train_mt_100_emb)\n",
        "X_val_zh_100_max = max_word_embeddings(zh_val_src_100_emb, zh_val_mt_100_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhbbsDdFFyWO",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE4p089dsp1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEDG9qjUF2YY",
        "colab_type": "text"
      },
      "source": [
        "### Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY1auosCuegb",
        "colab_type": "code",
        "outputId": "f3600039-60eb-4459-d650-7fe17585230c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_a, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_a)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "linear\n",
        "RMSE: 0.9023060200743632 Pearson 0.3072337367525771\n",
        "\n",
        "poly\n",
        "RMSE: 0.8993484622463825 Pearson 0.3044765902787262\n",
        "\n",
        "rbf\n",
        "RMSE: 0.8895045629309669 Pearson 0.3424205188758487\n",
        "\n",
        "sigmoid\n",
        "RMSE: 7.04363364235969 Pearson -0.03875077289090174\n",
        "\"\"\""
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "RMSE: 0.9023060200743632 Pearson 0.3072337367525771\n",
            "\n",
            "poly\n",
            "RMSE: 0.8993484622463825 Pearson 0.3044765902787262\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8895045629309669 Pearson 0.3424205188758487\n",
            "\n",
            "sigmoid\n",
            "RMSE: 7.04363364235969 Pearson -0.03875077289090174\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlinear\\nRMSE: 0.9023060200743632 Pearson 0.3072337367525771\\n\\npoly\\nRMSE: 0.8993484622463825 Pearson 0.3044765902787262\\n\\nrbf\\nRMSE: 0.8895045629309669 Pearson 0.3424205188758487\\n\\nsigmoid\\nRMSE: 7.04363364235969 Pearson -0.03875077289090174\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nHytkDwlz3z",
        "colab_type": "text"
      },
      "source": [
        "### Sum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6PSaergmfjf",
        "colab_type": "code",
        "outputId": "b7bdb2e1-bfa1-4c8f-f661-65a8c5dc1bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_s, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_s)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "linear\n",
        "RMSE: 0.9227835782009712 Pearson 0.2425756512117508\n",
        "\n",
        "poly\n",
        "RMSE: 0.9516944090249123 Pearson 0.1856020876506383\n",
        "\n",
        "rbf\n",
        "RMSE: 0.9054660793535703 Pearson 0.29358229219039883\n",
        "\n",
        "sigmoid\n",
        "RMSE: 33.540682964794215 Pearson -0.013899488606520101\n",
        "\"\"\""
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "RMSE: 0.9227835782009712 Pearson 0.2425756512117508\n",
            "\n",
            "poly\n",
            "RMSE: 0.9516944090249123 Pearson 0.1856020876506383\n",
            "\n",
            "rbf\n",
            "RMSE: 0.9054660793535703 Pearson 0.29358229219039883\n",
            "\n",
            "sigmoid\n",
            "RMSE: 33.540682964794215 Pearson -0.013899488606520101\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlinear\\nRMSE: 0.9227835782009712 Pearson 0.2425756512117508\\n\\npoly\\nRMSE: 0.9516944090249123 Pearson 0.1856020876506383\\n\\nrbf\\nRMSE: 0.9054660793535703 Pearson 0.29358229219039883\\n\\nsigmoid\\nRMSE: 33.540682964794215 Pearson -0.013899488606520101\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtlJk1Bz5jya",
        "colab_type": "text"
      },
      "source": [
        "### Min/Max\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC-LkWyjAv9n",
        "colab_type": "code",
        "outputId": "f119d51a-0814-4f94-ee95-09688cd655cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "print(\"min\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_min, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_min)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"max\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_max, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_max)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "min\n",
        "linear\n",
        "RMSE: 0.9143167236911504 Pearson 0.27536526116188104\n",
        "\n",
        "poly\n",
        "RMSE: 0.970271685744294 Pearson 0.23242310658976342\n",
        "\n",
        "rbf\n",
        "RMSE: 0.9025641754217032 Pearson 0.2973480407106239\n",
        "\n",
        "sigmoid\n",
        "RMSE: 28.280921526236867 Pearson 0.009983214811094767\n",
        "\n",
        "max\n",
        "linear\n",
        "RMSE: 0.9284620494004884 Pearson 0.2359812007567792\n",
        "\n",
        "poly\n",
        "RMSE: 1.0235373606067586 Pearson 0.17306578845193377\n",
        "\n",
        "rbf\n",
        "RMSE: 0.9079366185041642 Pearson 0.27905090847445657\n",
        "\n",
        "sigmoid\n",
        "RMSE: 28.406444719807993 Pearson -0.004419994996657859\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min\n",
            "linear\n",
            "RMSE: 0.9143167236911504 Pearson 0.27536526116188104\n",
            "\n",
            "poly\n",
            "RMSE: 0.970271685744294 Pearson 0.23242310658976342\n",
            "\n",
            "rbf\n",
            "RMSE: 0.9025641754217032 Pearson 0.2973480407106239\n",
            "\n",
            "sigmoid\n",
            "RMSE: 28.280921526236867 Pearson 0.009983214811094767\n",
            "\n",
            "max\n",
            "linear\n",
            "RMSE: 0.9284620494004884 Pearson 0.2359812007567792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qThYLeO7oJPB",
        "colab_type": "text"
      },
      "source": [
        "### Combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkpY7XYnoVr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# min + max\n",
        "X_train_100_mm = [sum(t, []) for t in zip(zh_train_src_100_min, zh_train_src_100_max, zh_train_mt_100_min, zh_train_mt_100_max)]\n",
        "X_train_zh_100_mm = np.array(X_train_100_mm)\n",
        "X_val_100_mm = [sum(t, []) for t in zip(zh_val_src_100_min, zh_val_src_100_max, zh_val_mt_100_min, zh_val_mt_100_max)]\n",
        "X_val_zh_100_mm = np.array(X_val_100_mm)\n",
        "\n",
        "# min + avg + max\n",
        "X_train_100_mam = [sum(t, []) for t in zip(zh_train_src_100_min, zh_train_src_100_a, zh_train_src_100_max, zh_train_mt_100_min, zh_train_mt_100_a, zh_train_mt_100_max)]\n",
        "X_train_zh_100_mam = np.array(X_train_100_mam)\n",
        "X_val_100_mam = [sum(t, []) for t in zip(zh_val_src_100_min, zh_val_src_100_a, zh_val_src_100_max, zh_val_mt_100_min, zh_val_mt_100_a, zh_val_mt_100_max)]\n",
        "X_val_zh_100_mam = np.array(X_val_100_mam)\n",
        "\n",
        "# avg + sum\n",
        "X_train_100_as = [sum(t, []) for t in zip(zh_train_src_100_a, zh_train_src_100_s, zh_train_mt_100_a, zh_train_mt_100_s)]\n",
        "X_train_zh_100_as = np.array(X_train_100_mam)\n",
        "X_val_100_as = [sum(t, []) for t in zip(zh_val_src_100_a, zh_val_src_100_s, zh_val_mt_100_a, zh_val_mt_100_s)]\n",
        "X_val_zh_100_as = np.array(X_val_100_mam)\n",
        "\n",
        "# min + avg + max + sum\n",
        "X_train_100_mams = [sum(t, []) for t in zip(zh_train_src_100_min, zh_train_src_100_a, zh_train_src_100_max, zh_train_src_100_s, zh_train_mt_100_min, zh_train_mt_100_a, zh_train_mt_100_max, zh_train_src_100_s)]\n",
        "X_train_zh_100_mams = np.array(X_train_100_mam)\n",
        "X_val_100_mams = [sum(t, []) for t in zip(zh_val_src_100_min, zh_val_src_100_a, zh_val_src_100_max, zh_val_src_100_s, zh_val_mt_100_min, zh_val_mt_100_a, zh_val_mt_100_max, zh_val_mt_100_s)]\n",
        "X_val_zh_100_mams = np.array(X_val_100_mam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMabHUiVo-o6",
        "colab_type": "code",
        "outputId": "76d1b619-9cc7-467d-af00-a4ffdba178b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        }
      },
      "source": [
        "print(\"min + max\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_mm, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_mm)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"min + avg + max\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_mam, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_mam)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"avg + sum\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_as, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_as)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "print(\"min + avg + max + sum\")\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh_100_mams, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh_100_mams)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n",
        "\"\"\"\n",
        "min + max\n",
        "linear\n",
        "RMSE: 0.9141733794206062 Pearson 0.27337556488854026\n",
        "\n",
        "poly\n",
        "RMSE: 0.9063297287258996 Pearson 0.31037822893487643\n",
        "\n",
        "rbf\n",
        "RMSE: 0.9050521266690811 Pearson 0.3130501459492051\n",
        "\n",
        "sigmoid\n",
        "RMSE: 3.584827555910887 Pearson -0.015479223808303745\n",
        "\n",
        "min + avg + max\n",
        "linear\n",
        "RMSE: 0.9081466259557258 Pearson 0.28795604452909246\n",
        "\n",
        "poly\n",
        "RMSE: 0.8962147090765858 Pearson 0.334701838648443\n",
        "\n",
        "rbf\n",
        "RMSE: 0.8964166238974365 Pearson 0.3355584468671853\n",
        "\n",
        "sigmoid\n",
        "RMSE: 2.647039384739339 Pearson 0.006553679583206628\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min + max\n",
            "linear\n",
            "RMSE: 0.9141733794206062 Pearson 0.27337556488854026\n",
            "\n",
            "poly\n",
            "RMSE: 0.9063297287258996 Pearson 0.31037822893487643\n",
            "\n",
            "rbf\n",
            "RMSE: 0.9050521266690811 Pearson 0.3130501459492051\n",
            "\n",
            "sigmoid\n",
            "RMSE: 3.584827555910887 Pearson -0.015479223808303745\n",
            "\n",
            "min + avg + max\n",
            "linear\n",
            "RMSE: 0.9081466259557258 Pearson 0.28795604452909246\n",
            "\n",
            "poly\n",
            "RMSE: 0.8962147090765858 Pearson 0.334701838648443\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8964166238974365 Pearson 0.3355584468671853\n",
            "\n",
            "sigmoid\n",
            "RMSE: 2.647039384739339 Pearson 0.006553679583206628\n",
            "\n",
            "avg + sum\n",
            "linear\n",
            "RMSE: 0.9081466259557258 Pearson 0.28795604452909246\n",
            "\n",
            "poly\n",
            "RMSE: 0.8962147090765858 Pearson 0.334701838648443\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8964166238974365 Pearson 0.3355584468671853\n",
            "\n",
            "sigmoid\n",
            "RMSE: 2.647039384739339 Pearson 0.006553679583206628\n",
            "\n",
            "min + avg + max + sum\n",
            "linear\n",
            "RMSE: 0.9081466259557258 Pearson 0.28795604452909246\n",
            "\n",
            "poly\n",
            "RMSE: 0.8962147090765858 Pearson 0.334701838648443\n",
            "\n",
            "rbf\n",
            "RMSE: 0.8964166238974365 Pearson 0.3355584468671853\n",
            "\n",
            "sigmoid\n",
            "RMSE: 2.647039384739339 Pearson 0.006553679583206628\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmin + max\\nlinear\\nRMSE: 0.9165262212864648 Pearson 0.26668369681069803\\n\\npoly\\nRMSE: 0.9081786905379852 Pearson 0.3058041114768354\\n\\nrbf\\nRMSE: 0.9084429289156349 Pearson 0.30464644770878846\\n\\nsigmoid\\nRMSE: 3.5248833190245237 Pearson -0.006792767476776504\\n\\nmin + avg + max\\nlinear\\nRMSE: 0.9081244309157551 Pearson 0.28851234087420935\\n\\npoly\\nRMSE: 0.8982943971746072 Pearson 0.3296975280939544\\n\\nrbf\\nRMSE: 0.8992479975159785 Pearson 0.3292233306043897\\n\\nsigmoid\\nRMSE: 2.600000956750181 Pearson 0.014142349847365135\\n\\navg + sum\\nlinear\\nRMSE: 0.9081244309157551 Pearson 0.28851234087420935\\n\\npoly\\nRMSE: 0.8982943971746072 Pearson 0.3296975280939544\\n\\nrbf\\nRMSE: 0.8992479975159785 Pearson 0.3292233306043897\\n\\nsigmoid\\nRMSE: 2.600000956750181 Pearson 0.014142349847365135\\n\\nmin + avg + max + sum\\nlinear\\nRMSE: 0.9081244309157551 Pearson 0.28851234087420935\\n\\npoly\\nRMSE: 0.8982943971746072 Pearson 0.3296975280939544\\n\\nrbf\\nRMSE: 0.8992479975159785 Pearson 0.3292233306043897\\n\\nsigmoid\\nRMSE: 2.600000956750181 Pearson 0.014142349847365135\\n\\nmin + max\\nlinear\\nRMSE: 0.9168107744473513 Pearson 0.2688232065879311\\n\\npoly\\nRMSE: 0.9083695575582953 Pearson 0.3043574716485458\\n\\nrbf\\nRMSE: 0.9062093063265356 Pearson 0.31087546737352734\\n\\nsigmoid\\nRMSE: 3.625265410743996 Pearson 0.0026252300859921688\\n\\nmin + avg + max\\nlinear\\nRMSE: 0.9062381633887625 Pearson 0.2922549246830163\\n\\npoly\\nRMSE: 0.8985827264208488 Pearson 0.3290153810259093\\n\\nrbf\\nRMSE: 0.8984560405790161 Pearson 0.3311185677391374\\n\\nsigmoid\\nRMSE: 2.7197714896675778 Pearson 0.024042115406686545\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Lt3AWYxZ19",
        "colab_type": "text"
      },
      "source": [
        "## FFNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0Op0Q-gxl4D",
        "colab_type": "text"
      },
      "source": [
        "### Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sez0JE9NxoY-",
        "colab_type": "code",
        "outputId": "67824ad2-4bf8-468d-c8cb-9a129562724d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import time\n",
        "import math\n",
        "\n",
        "###############\n",
        "# Torch setup #\n",
        "###############\n",
        "print('Torch version: {}, CUDA: {}'.format(torch.__version__, torch.version.cuda))\n",
        "cuda_available = torch.cuda.is_available()\n",
        "if not torch.cuda.is_available():\n",
        "  print('WARNING: You may want to change the runtime to GPU for Neural LM experiments!')\n",
        "  DEVICE = 'cpu'\n",
        "else:\n",
        "  DEVICE = 'cuda:0'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version: 1.4.0, CUDA: 10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y9ckrORl4ux",
        "colab_type": "text"
      },
      "source": [
        "### Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoVLrvbfUenV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "\n",
        "def ffln(train, valid, hidden_sizes=[64], batch_size=64, epochs=100, weight_decay=0, verbose=2, early_stop=True):\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  # Setup NN\n",
        "  sizes = [train[0].size] + hidden_sizes\n",
        "  prev_s = None\n",
        "  layers = []\n",
        "  for s in sizes:\n",
        "    if prev_s:\n",
        "      layers.append(nn.Linear(prev_s, s).cuda())\n",
        "      layers.append(nn.LeakyReLU().cuda())\n",
        "    prev_s = s\n",
        "  layers.append(nn.Linear(prev_s, 1).cuda())\n",
        "\n",
        "  net = nn.Sequential(*layers)\n",
        "  \n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=weight_decay)\n",
        "  loss_func = nn.MSELoss()\n",
        "\n",
        "  ## Setup inputs\n",
        "  net_X = Variable(torch.from_numpy(train))\n",
        "  net_y = Variable(torch.from_numpy(y_train_zh))\n",
        "  torch_dataset = Data.TensorDataset(net_X, net_y)\n",
        "  \n",
        "  loader = Data.DataLoader(\n",
        "      dataset=torch_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=2,\n",
        "  )\n",
        "  \n",
        "  net = net.float()\n",
        "\n",
        "  ## Training\n",
        "  final_epoch = 0\n",
        "  last_pearson = None\n",
        "  for epoch in range(epochs):\n",
        "    training_loss = 0\n",
        "    for step, (batch_x, batch_y) in enumerate(loader):\n",
        "      b_x = Variable(batch_x.float().to(DEVICE))\n",
        "      b_y = Variable(batch_y.float().to(DEVICE))\n",
        "      prediction = torch.flatten(net(b_x))\n",
        "      loss = loss_func(prediction, b_y)\n",
        "      training_loss += mean_squared_error(b_y.cpu().detach().numpy(), prediction.cpu().detach().numpy())\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    # Evaluate validation loss every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "      training_loss = training_loss / step\n",
        "      with torch.no_grad():\n",
        "        net.eval()\n",
        "        net_val = Variable(torch.from_numpy(valid).float().to(DEVICE))\n",
        "        pred = torch.flatten(net.forward(net_val)).cpu().detach().numpy()\n",
        "        net.train()\n",
        "        pearson = pearsonr(y_val_zh, pred)\n",
        "        # If using early stopping, then stop when validation loss has increased\n",
        "        # since the last time it was checked.\n",
        "        if last_pearson and early_stop and last_pearson > pearson[0]:\n",
        "          final_epoch = epoch\n",
        "          break\n",
        "        else:\n",
        "          last_pearson = pearson[0]\n",
        "        if verbose >= 2:\n",
        "          print(f\"Epoch {epoch} Training Loss: {training_loss}, Pearson Score: {pearson[0]}, MSE: {mean_squared_error(y_val_zh, pred)}\")\n",
        "    final_epoch = epoch\n",
        "  \n",
        "  # Return the final validation Pearson score\n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "    net_val = Variable(torch.from_numpy(valid).float().to(DEVICE))\n",
        "    pred = torch.flatten(net.forward(net_val)).cpu().detach().numpy()\n",
        "    net_train = Variable(torch.from_numpy(train).float().to(DEVICE))\n",
        "    pred_t = torch.flatten(net.forward(net_train)).cpu().detach().numpy()\n",
        "    net.train()\n",
        "    pearson = pearsonr(y_val_zh, pred)\n",
        "    pearson_t = pearsonr(y_train_zh, pred_t)\n",
        "    if verbose >= 1:\n",
        "      print(f\"Final Validation Pearson Score: {pearson[0]}\")\n",
        "    return pearson[0], pearson_t[0], final_epoch, net\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYbGUzPmVAk",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search with One Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-K2s36ArCcW",
        "colab_type": "code",
        "outputId": "21a72b67-5ae1-4a7b-87a5-6acde68aca06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        }
      },
      "source": [
        "hidden_sizes = [32, 64, 128, 256, 512]\n",
        "batch_sizes = [32, 64, 128, 256, 512]\n",
        "weight_decay = 0.001\n",
        "\n",
        "print(\"| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\")\n",
        "print(\"|---|---|---|---|---|\")\n",
        "for h in hidden_sizes:\n",
        "  for b in batch_sizes:\n",
        "    p, p_t, e, _ = ffln(X_train_zh_100_a, X_val_zh_100_a, hidden_sizes=[h], batch_size=b, epochs=500, verbose=0, weight_decay=weight_decay)\n",
        "    print(f\"| {h} | {b} | {e} | {p_t} | {p} |\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
            "|---|---|---|---|---|\n",
            "| 32 | 32 | 90 | 0.28910033875627006 | 0.26650870390463255 |\n",
            "| 32 | 64 | 60 | 0.28783177387349757 | 0.26429830239885116 |\n",
            "| 32 | 128 | 110 | 0.28867307595844666 | 0.2655793457472889 |\n",
            "| 32 | 256 | 110 | 0.28750555067685357 | 0.2636813566968737 |\n",
            "| 32 | 512 | 170 | 0.2884581717795725 | 0.26508557152058276 |\n",
            "| 64 | 32 | 40 | 0.2867930311266828 | 0.26372049701310835 |\n",
            "| 64 | 64 | 40 | 0.2867451608821309 | 0.26402893717198245 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-dfdb3d2f1bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_zh_100_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_zh_100_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"| {h} | {b} | {e} | {p_t} | {p} |\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-c5b80d3e4fd7>\u001b[0m in \u001b[0;36mffln\u001b[0;34m(train, valid, hidden_sizes, batch_size, epochs, weight_decay, verbose, early_stop)\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       \u001b[0mtraining_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
            "    close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMmUggkzQjiT",
        "colab_type": "text"
      },
      "source": [
        "#### Results from One Layer Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBgm_uzUQqNk",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opediEhIPETq",
        "colab_type": "text"
      },
      "source": [
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| 32 | 32 | 70 | 0.48299684617124355 | 0.35568926872569034 |\n",
        "| 32 | 64 | 90 | 0.47402861701221255 | 0.35484624967389417 |\n",
        "| 32 | 128 | 120 | 0.46769460605137325 | 0.354001807956961 |\n",
        "| 32 | 256 | 140 | 0.4451696316549598 | 0.35419410833769244 |\n",
        "| 32 | 512 | 200 | 0.4439794759089259 | 0.35376695722948476 |\n",
        "| 64 | 32 | 50 | 0.5050977337865824 | 0.35642318172718346 |\n",
        "| 64 | 64 | 60 | 0.48461355581325777 | 0.3576238432523523 |\n",
        "| 64 | 128 | 90 | 0.4899753302682104 | 0.3561842136832902 |\n",
        "| 64 | 256 | 120 | 0.48020191069491663 | 0.35734185721004297 |\n",
        "| 64 | 512 | 200 | 0.496231710595813 | 0.35519182285016304 |\n",
        "| 128 | 32 | 40 | 0.5300551965029648 | 0.35997446559039575 |\n",
        "| 128 | 64 | 50 | 0.5153791051222808 | 0.3611079819831347 |\n",
        "| 128 | 128 | 80 | 0.5344236286008841 | 0.3616800834614517 |\n",
        "| 128 | 256 | 100 | 0.5108236652821491 | 0.36388654741407084 |\n",
        "| 128 | 512 | 130 | 0.4962281367272859 | **0.3639496293878147** |\n",
        "| 256 | 32 | 30 | 0.5584957328071897 | 0.36131444904084803 |\n",
        "| 256 | 64 | 40 | 0.5495577458050304 | 0.3600462018518822 |\n",
        "| 256 | 128 | 50 | 0.5320562994631689 | 0.36105712427084846 |\n",
        "| 256 | 256 | 70 | 0.5245011760276505 | 0.36195596951857956 |\n",
        "| 256 | 512 | 90 | 0.5054828308375421 | 0.3613732695075446 |\n",
        "| 512 | 32 | 20 | 0.556784413338219 | 0.359580644331573 |\n",
        "| 512 | 64 | 40 | 0.6384220275150658 | 0.3584139600716416 |\n",
        "| 512 | 128 | 50 | 0.6129006760987404 | 0.35740668383572766 |\n",
        "| 512 | 256 | 60 | 0.5723914156685365 | 0.3580794536925124 |\n",
        "| 512 | 512 | 70 | 0.5298419125443378 | 0.35974505667758333 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFYpqwQRaT5J",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0.01\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| 32 | 32 | 90 | 0.45100997469770016 | 0.3582803012815051 |\n",
        "| 32 | 64 | 120 | 0.4503648686536401 | 0.3612327906812081 |\n",
        "| 32 | 128 | 140 | 0.43456235490520323 | 0.35732681839123887 |\n",
        "| 32 | 256 | 140 | 0.40911696781469237 | 0.35051562078207565 |\n",
        "| 32 | 512 | 380 | 0.4573539398883728 | 0.36226482868230936 |\n",
        "| 64 | 32 | 110 | 0.5150871707999816 | 0.3638623578357723 |\n",
        "| 64 | 64 | 140 | 0.5101560100532213 | 0.36533322301784016 |\n",
        "| 64 | 128 | 190 | 0.501001080294028 | 0.364107813010426 |\n",
        "| 64 | 256 | 170 | 0.45934007507494534 | 0.3602363082137179 |\n",
        "| 64 | 512 | 310 | 0.4794312797086712 | 0.36314950087155257 |\n",
        "| 128 | 32 | 80 | 0.5254772408655755 | 0.36413656838985187 |\n",
        "| 128 | 64 | 80 | 0.4924648511059825 | **0.36534145933484247** |\n",
        "| 128 | 128 | 110 | 0.4905548920330267 | 0.3652737593370598 |\n",
        "| 128 | 256 | 120 | 0.4596690298995526 | 0.3607400995139613 |\n",
        "| 128 | 512 | 190 | 0.4703827088565318 | 0.35990875219965446 |\n",
        "| 256 | 32 | 50 | 0.5078747999445999 | 0.35920905100898687 |\n",
        "| 256 | 64 | 70 | 0.512184065421008 | 0.3620287430543616 |\n",
        "| 256 | 128 | 70 | 0.47870476273285056 | 0.3620495830468129 |\n",
        "| 256 | 256 | 120 | 0.49626925570140756 | 0.36270427046399956 |\n",
        "| 256 | 512 | 150 | 0.47698570786025907 | 0.35977281719496734 |\n",
        "| 512 | 32 | 50 | 0.5401908906558154 | 0.3570021396696617 |\n",
        "| 512 | 64 | 50 | 0.5072977378281833 | 0.3605957816283808 |\n",
        "| 512 | 128 | 90 | 0.5415603401013815 | 0.36270088337099327 |\n",
        "| 512 | 256 | 90 | 0.4955292147759141 | 0.3635272873351458 |\n",
        "| 512 | 512 | 120 | 0.48188509952735753 | 0.36111544420801234 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meOE1MwBKnp7",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0.001\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| 32 | 32 | 80 | 0.49336796221998863 | 0.3595207129989028 |\n",
        "| 32 | 64 | 90 | 0.4686487002414254 | 0.3582774027958467 |\n",
        "| 32 | 128 | 150 | 0.489292727653548 | 0.3600779802129854 |\n",
        "| 32 | 256 | 180 | 0.4674018276179893 | 0.35810249130930877 |\n",
        "| 32 | 512 | 280 | 0.47452774933243747 | 0.36091831430719745 |\n",
        "| 64 | 32 | 50 | 0.49944192717692193 | 0.35990356184421063 |\n",
        "| 64 | 64 | 80 | 0.5136684848041514 | 0.35919112510262313 |\n",
        "| 64 | 128 | 90 | 0.4849341517291386 | 0.3586888914929235 |\n",
        "| 64 | 256 | 150 | 0.5024117906414646 | 0.36029578906596255 |\n",
        "| 64 | 512 | 200 | 0.49155204667787317 | 0.3579592555397539 |\n",
        "| 128 | 32 | 40 | 0.5212065808627342 | **0.3655701207861885** |\n",
        "| 128 | 64 | 60 | 0.5320505549107768 | 0.3629479167009998 |\n",
        "| 128 | 128 | 80 | 0.5274899085367852 | 0.36497695862740553 |\n",
        "| 128 | 256 | 100 | 0.5040941793383894 | 0.36454298354300246 |\n",
        "| 128 | 512 | 120 | 0.4780463011632069 | 0.36431483254699737 |\n",
        "| 256 | 32 | 40 | 0.5933778761141248 | 0.36153553996319515 |\n",
        "| 256 | 64 | 40 | 0.5345114685466408 | 0.36418110838174944 |\n",
        "| 256 | 128 | 70 | 0.576063105124408 | 0.3638639717583646 |\n",
        "| 256 | 256 | 70 | 0.5120956157535899 | 0.3650715612822175 |\n",
        "| 256 | 512 | 110 | 0.5253553772479195 | 0.36316481818471735 |\n",
        "| 512 | 32 | 30 | 0.6222180693364254 | 0.36158233314745136 |\n",
        "| 512 | 64 | 50 | 0.6632538171675477 | 0.35826857180175015 |\n",
        "| 512 | 128 | 50 | 0.591131995809352 | 0.36331944190464277 |\n",
        "| 512 | 256 | 70 | 0.5824858191970835 | 0.3622091989794235 |\n",
        "| 512 | 512 | 90 | 0.5600560401158342 | 0.36213104755775855 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trc9h5_WSW2A",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0.0001\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| 32 | 32 | 70 | 0.4830532067296478 | 0.3555060634157582 |\n",
        "| 32 | 64 | 90 | 0.47275643227640973 | 0.3543644805032278 |\n",
        "| 32 | 128 | 120 | 0.46714670011179266 | 0.3544942159923127 |\n",
        "| 32 | 256 | 180 | 0.47071218804547743 | 0.3566361717224038 |\n",
        "| 32 | 512 | 240 | 0.46171948937276924 | 0.35494854249653307 |\n",
        "| 64 | 32 | 50 | 0.5046060631003529 | 0.3561336258710358 |\n",
        "| 64 | 64 | 70 | 0.5006609401752118 | 0.35764026845550645 |\n",
        "| 64 | 128 | 90 | 0.48977853618588074 | 0.35660579119065317 |\n",
        "| 64 | 256 | 130 | 0.4884750707106939 | 0.35750823890033995 |\n",
        "| 64 | 512 | 160 | 0.47038291546523764 | 0.3553940025455295 |\n",
        "| 128 | 32 | 40 | 0.5296528806458696 | 0.36051136999747474 |\n",
        "| 128 | 64 | 50 | 0.5138629835356658 | 0.3614184783217593 |\n",
        "| 128 | 128 | 80 | 0.5340628954126573 | 0.36152075923793214 |\n",
        "| 128 | 256 | 100 | 0.5101477581738477 | 0.3628146586490763 |\n",
        "| 128 | 512 | 130 | 0.4954820923170049 | **0.3635680289756267** |\n",
        "| 256 | 32 | 30 | 0.5569831868147893 | 0.36280076970257435 |\n",
        "| 256 | 64 | 40 | 0.5483943339029308 | 0.36122493157130764 |\n",
        "| 256 | 128 | 60 | 0.5616400250894735 | 0.3620758934990978 |\n",
        "| 256 | 256 | 70 | 0.5231049330654992 | 0.3630111659792139 |\n",
        "| 256 | 512 | 110 | 0.5381738236831985 | 0.36019270269875187 |\n",
        "| 512 | 32 | 20 | 0.554446011862658 | 0.3598765906754196 |\n",
        "| 512 | 64 | 40 | 0.6356313286771624 | 0.361338152367777 |\n",
        "| 512 | 128 | 50 | 0.6101331943464575 | 0.3589041646949778 |\n",
        "| 512 | 256 | 60 | 0.5699815807507783 | 0.3602698468993568 |\n",
        "| 512 | 512 | 70 | 0.5273997386224675 | 0.3608117223004388 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOy1XHrQmYVS",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search with Two Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8p0Zw-jR_Xq",
        "colab_type": "code",
        "outputId": "7de3a567-3e56-4a1a-f7ad-c1dda0df3268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import itertools\n",
        "\n",
        "sizes = [32, 64, 128, 256, 512]\n",
        "batch_sizes = [32, 64, 128, 256, 512]\n",
        "weight_decay=0.01\n",
        "sizes = list(list(t) for t in itertools.product(sizes, sizes))\n",
        "search = list(itertools.product(sizes, batch_sizes))\n",
        "\n",
        "print(\"| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\")\n",
        "print(\"|---|---|---|---|---|\")\n",
        "for s, b in search:\n",
        "  p, p_t, e, _ = ffln(X_train_zh_100_a, X_val_zh_100_a, hidden_sizes=s, batch_size=b, epochs=500, verbose=0, weight_decay=weight_decay)\n",
        "  print(f\"| {s} | {b} | {e} | {p_t} | {p} |\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
            "|---|---|---|---|---|\n",
            "| [64, 64] | 512 | 210 | 0.5227163099320284 | 0.36775365203777477 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqr597ydaizV",
        "colab_type": "text"
      },
      "source": [
        "#### Results from Two layer Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FPWondualpq",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0\n",
        "\n",
        "\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| [32, 32] | 32 | 40 | 0.5081770770385975 | 0.34801201441426727 |\n",
        "| [32, 32] | 64 | 50 | 0.4897875190023316 | 0.35180442781202537 |\n",
        "| [32, 32] | 128 | 60 | 0.471319249596159 | 0.35216127932418095 |\n",
        "| [32, 32] | 256 | 80 | 0.4592414925340225 | 0.3519866572138941 |\n",
        "| [32, 32] | 512 | 120 | 0.46425772682932503 | 0.35151247242958056 |\n",
        "| [32, 64] | 32 | 30 | 0.4796861792859908 | 0.3498461575667321 |\n",
        "| [32, 64] | 64 | 50 | 0.5138079761615646 | 0.35160007685387956 |\n",
        "| [32, 64] | 128 | 60 | 0.49111954140700154 | 0.35501585078311043 |\n",
        "| [32, 64] | 256 | 80 | 0.48100806849344646 | 0.3527689110013705 |\n",
        "| [32, 64] | 512 | 110 | 0.47345423786359253 | 0.35092546076354725 |\n",
        "| [32, 128] | 32 | 30 | 0.5008741717910612 | 0.33964560616524064 |\n",
        "| [32, 128] | 64 | 40 | 0.5011052842994936 | 0.33933330300888603 |\n",
        "| [32, 128] | 128 | 40 | 0.4582418901142382 | 0.34739491249119014 |\n",
        "| [32, 128] | 256 | 60 | 0.4621263640810455 | 0.3465269388711895 |\n",
        "| [32, 128] | 512 | 90 | 0.465597542007843 | 0.3457915977785479 |\n",
        "| [32, 256] | 32 | 30 | 0.5329860116715605 | 0.34357907783261743 |\n",
        "| [32, 256] | 64 | 30 | 0.4865428087678733 | 0.35572479528131656 |\n",
        "| [32, 256] | 128 | 40 | 0.48052476891754525 | 0.3543011238452829 |\n",
        "| [32, 256] | 256 | 60 | 0.4860260578215678 | 0.3525535644582506 |\n",
        "| [32, 256] | 512 | 80 | 0.46862449033538783 | 0.3529549622986453 |\n",
        "| [32, 512] | 32 | 20 | 0.5055240087029065 | 0.32601374416241413 |\n",
        "| [32, 512] | 64 | 30 | 0.5188875280925833 | 0.3179975788422171 |\n",
        "| [32, 512] | 128 | 30 | 0.4699261060747212 | 0.33679649307565207 |\n",
        "| [32, 512] | 256 | 40 | 0.455737890436249 | 0.3344219385019655 |\n",
        "| [32, 512] | 512 | 60 | 0.4599190009601511 | 0.3328937301128072 |\n",
        "| [64, 32] | 32 | 30 | 0.5355110287248864 | 0.3478778050987554 |\n",
        "| [64, 32] | 64 | 40 | 0.5264094792582278 | 0.34376367455800805 |\n",
        "| [64, 32] | 128 | 40 | 0.4779046113722663 | 0.35275295871734835 |\n",
        "| [64, 32] | 256 | 60 | 0.4822133899414166 | 0.3495061148312315 |\n",
        "| [64, 32] | 512 | 80 | 0.46967093639034196 | 0.35023971412168714 |\n",
        "| [64, 64] | 32 | 30 | 0.548199615084581 | 0.34246616954252085 |\n",
        "| [64, 64] | 64 | 40 | 0.5384632016469784 | 0.34812512840948795 |\n",
        "| [64, 64] | 128 | 50 | 0.5161190781765183 | 0.355902634793197 |\n",
        "| [64, 64] | 256 | 60 | 0.4835348501398026 | 0.3598794758880293 |\n",
        "| [64, 64] | 512 | 90 | 0.489188526573068 | **0.3620220512957468** |\n",
        "| [64, 128] | 32 | 20 | 0.5238038214951334 | 0.3414280655711996 |\n",
        "| [64, 128] | 64 | 30 | 0.5380299500555019 | 0.3414050223679859 |\n",
        "| [64, 128] | 128 | 40 | 0.5335752007421125 | 0.34065157380623134 |\n",
        "| [64, 128] | 256 | 50 | 0.5066219234904855 | 0.3460378003673324 |\n",
        "| [64, 128] | 512 | 60 | 0.4742384537082817 | 0.35069956841809286 |\n",
        "| [64, 256] | 32 | 20 | 0.5211886039936586 | 0.352351231939332 |\n",
        "| [64, 256] | 64 | 30 | 0.5370382293087058 | 0.3510801946890659 |\n",
        "| [64, 256] | 128 | 40 | 0.53734716468934 | 0.3455473606403491 |\n",
        "| [64, 256] | 256 | 50 | 0.5112961739048506 | 0.3503522025895193 |\n",
        "| [64, 256] | 512 | 60 | 0.4819179802638056 | 0.35460296958205234 |\n",
        "| [64, 512] | 32 | 20 | 0.5621780968739095 | 0.3268183990223234 |\n",
        "| [64, 512] | 64 | 20 | 0.5067892731089352 | 0.34589821245923974 |\n",
        "| [64, 512] | 128 | 30 | 0.5261678086444983 | 0.34052843629794427 |\n",
        "| [64, 512] | 256 | 40 | 0.511546069960251 | 0.34396647797791835 |\n",
        "| [64, 512] | 512 | 50 | 0.48457831123432826 | 0.3525369834181648 |\n",
        "| [128, 32] | 32 | 30 | 0.6039961285897729 | 0.34359048868395253 |\n",
        "| [128, 32] | 64 | 40 | 0.5985050322190164 | 0.3402627269843407 |\n",
        "| [128, 32] | 128 | 50 | 0.5794019327922569 | 0.33478221115521123 |\n",
        "| [128, 32] | 256 | 70 | 0.5739033109847669 | 0.3387409348176428 |\n",
        "| [128, 32] | 512 | 80 | 0.5175772339746831 | 0.3421137656130536 |\n",
        "| [128, 64] | 32 | 20 | 0.5542290956403353 | 0.33649332324188325 |\n",
        "| [128, 64] | 64 | 30 | 0.5780841307041461 | 0.3313689178064872 |\n",
        "| [128, 64] | 128 | 30 | 0.5060397782798773 | 0.3463739872278888 |\n",
        "| [128, 64] | 256 | 50 | 0.5388824546976178 | 0.34355298558608943 |\n",
        "| [128, 64] | 512 | 60 | 0.49846153608787913 | 0.3498538755132095 |\n",
        "| [128, 128] | 32 | 20 | 0.5969323088625645 | 0.3383213238043019 |\n",
        "| [128, 128] | 64 | 30 | 0.62310606700902 | 0.3313764363749702 |\n",
        "| [128, 128] | 128 | 30 | 0.549741282163187 | 0.3430542067484068 |\n",
        "| [128, 128] | 256 | 40 | 0.5309624665649803 | 0.35104187354270583 |\n",
        "| [128, 128] | 512 | 60 | 0.5417449906898956 | 0.3491107934108335 |\n",
        "| [128, 256] | 32 | 20 | 0.6181378488856449 | 0.32070855561961215 |\n",
        "| [128, 256] | 64 | 20 | 0.5530574362825813 | 0.3378616066308183 |\n",
        "| [128, 256] | 128 | 30 | 0.5681812442064847 | 0.33457707263754705 |\n",
        "| [128, 256] | 256 | 40 | 0.5519286224378426 | 0.34162024055503426 |\n",
        "| [128, 256] | 512 | 50 | 0.519250675395476 | 0.3451956541699298 |\n",
        "| [128, 512] | 32 | 20 | 0.6552514574466162 | 0.3172032401036353 |\n",
        "| [128, 512] | 64 | 20 | 0.582892693334241 | 0.32710717987408827 |\n",
        "| [128, 512] | 128 | 30 | 0.6026291473016793 | 0.33431984845220336 |\n",
        "| [128, 512] | 256 | 40 | 0.5819287870427984 | 0.3409575726043858 |\n",
        "| [128, 512] | 512 | 50 | 0.5503226802663136 | 0.34572438556683316 |\n",
        "| [256, 32] | 32 | 20 | 0.6178103322183633 | 0.3477664372973361 |\n",
        "| [256, 32] | 64 | 30 | 0.6453541666408443 | 0.34417797447377696 |\n",
        "| [256, 32] | 128 | 40 | 0.6381036307641387 | 0.35172147458672287 |\n",
        "| [256, 32] | 256 | 50 | 0.6060682963068668 | 0.35192347999913787 |\n",
        "| [256, 32] | 512 | 70 | 0.5941857295209115 | 0.35653716958127984 |\n",
        "| [256, 64] | 32 | 20 | 0.6508446412326873 | 0.3354972318221595 |\n",
        "| [256, 64] | 64 | 20 | 0.5695339984364156 | 0.3537229823938767 |\n",
        "| [256, 64] | 128 | 30 | 0.5900300449032189 | 0.3504856280265393 |\n",
        "| [256, 64] | 256 | 40 | 0.5647273719453317 | 0.3531712153192139 |\n",
        "| [256, 64] | 512 | 50 | 0.5255412586214809 | 0.36046624092422386 |\n",
        "| [256, 128] | 32 | 20 | 0.7121633395472036 | 0.3263041137119077 |\n",
        "| [256, 128] | 64 | 20 | 0.6226772535504698 | 0.34062914405298883 |\n",
        "| [256, 128] | 128 | 30 | 0.6488284208723305 | 0.3331483268104295 |\n",
        "| [256, 128] | 256 | 40 | 0.6260847823034719 | 0.3418160957687894 |\n",
        "| [256, 128] | 512 | 50 | 0.5782757714923286 | 0.34883211590181995 |\n",
        "| [256, 256] | 32 | 20 | 0.7422068061006223 | 0.3139725271543865 |\n",
        "| [256, 256] | 64 | 20 | 0.6493067998299227 | 0.3300058666775696 |\n",
        "| [256, 256] | 128 | 30 | 0.6875151887576874 | 0.32048344192303646 |\n",
        "| [256, 256] | 256 | 30 | 0.5732933370245789 | 0.34541468268612213 |\n",
        "| [256, 256] | 512 | 40 | 0.5495634419072722 | 0.34588723505781543 |\n",
        "| [256, 512] | 32 | 20 | 0.782500496555452 | 0.2732122634388016 |\n",
        "| [256, 512] | 64 | 20 | 0.6925983481652366 | 0.31086376353851425 |\n",
        "| [256, 512] | 128 | 20 | 0.6053920409623933 | 0.33602055791937624 |\n",
        "| [256, 512] | 256 | 30 | 0.6129793417745335 | 0.3304361808171883 |\n",
        "| [256, 512] | 512 | 40 | 0.5906397087884229 | 0.3383302899338092 |\n",
        "| [512, 32] | 32 | 20 | 0.7473526096724578 | 0.3210849760341188 |\n",
        "| [512, 32] | 64 | 20 | 0.6463424365514489 | 0.34960037100969105 |\n",
        "| [512, 32] | 128 | 30 | 0.6736019797203484 | 0.3456837061484702 |\n",
        "| [512, 32] | 256 | 40 | 0.6471314103492297 | 0.351719074447624 |\n",
        "| [512, 32] | 512 | 50 | 0.5940306228931375 | 0.3585976167016458 |\n",
        "| [512, 64] | 32 | 20 | 0.7801629048283105 | 0.3212583291037159 |\n",
        "| [512, 64] | 64 | 20 | 0.6815954287895202 | 0.33231715046311944 |\n",
        "| [512, 64] | 128 | 30 | 0.714064295599162 | 0.3284033861906422 |\n",
        "| [512, 64] | 256 | 30 | 0.5955503211525276 | 0.34967776659967015 |\n",
        "| [512, 64] | 512 | 40 | 0.5677400561504948 | 0.35028135079944817 |\n",
        "| [512, 128] | 32 | 20 | 0.8260028614447924 | 0.2953251952259495 |\n",
        "| [512, 128] | 64 | 20 | 0.7254102927038344 | 0.3249371086660587 |\n",
        "| [512, 128] | 128 | 20 | 0.624912277963159 | 0.34015650139658354 |\n",
        "| [512, 128] | 256 | 30 | 0.6423050217988907 | 0.3433596816806615 |\n",
        "| [512, 128] | 512 | 40 | 0.6151948846882693 | 0.34232623684709085 |\n",
        "| [512, 256] | 32 | 20 | 0.8792761671458663 | 0.25363890459228017 |\n",
        "| [512, 256] | 64 | 20 | 0.7913154856750211 | 0.2780646408203931 |\n",
        "| [512, 256] | 128 | 20 | 0.6754520532232722 | 0.32230029450889075 |\n",
        "| [512, 256] | 256 | 20 | 0.5636523483204313 | 0.34393162091158713 |\n",
        "| [512, 256] | 512 | 30 | 0.5734633023001962 | 0.34435823604452725 |\n",
        "| [512, 512] | 32 | 20 | 0.8998848099071178 | 0.23402208140250982 |\n",
        "| [512, 512] | 64 | 20 | 0.8224416560399235 | 0.2723810253666723 |\n",
        "| [512, 512] | 128 | 20 | 0.7184820066660945 | 0.30443170370453576 |\n",
        "| [512, 512] | 256 | 20 | 0.5961999576004962 | 0.34077235290976854 |\n",
        "| [512, 512] | 512 | 30 | 0.6104589519968133 | 0.3364864410301728 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeN8eCjQSgn8",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0.01\n",
        "\n",
        "\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| [32, 32] | 32 | 80 | 0.4768371156481136 | 0.3472105421814501 |\n",
        "| [32, 32] | 64 | 80 | 0.4412990560016324 | 0.3490910295584378 |\n",
        "| [32, 32] | 128 | 130 | 0.46320460333932084 | 0.35604428366231206 |\n",
        "| [32, 32] | 256 | 200 | 0.47043516351786646 | 0.3544688086342531 |\n",
        "| [32, 32] | 512 | 250 | 0.46393373094097495 | 0.358283666133919 |\n",
        "| [32, 64] | 32 | 70 | 0.47664527627112285 | 0.3511953535231789 |\n",
        "| [32, 64] | 64 | 90 | 0.4629009798187991 | 0.3427573148099104 |\n",
        "| [32, 64] | 128 | 120 | 0.4530688238469185 | 0.34261743780722276 |\n",
        "| [32, 64] | 256 | 160 | 0.4549851002315548 | 0.3471089321762645 |\n",
        "| [32, 64] | 512 | 300 | 0.4918908005658059 | 0.3550438246242377 |\n",
        "| [32, 128] | 32 | 40 | 0.45640237977557246 | 0.35260709946727226 |\n",
        "| [32, 128] | 64 | 70 | 0.48555743851648625 | 0.35259276745571405 |\n",
        "| [32, 128] | 128 | 80 | 0.4608224613616029 | 0.3532852517865351 |\n",
        "| [32, 128] | 256 | 120 | 0.46475468189265484 | 0.35626144013915956 |\n",
        "| [32, 128] | 512 | 200 | 0.4852847485078734 | 0.3530608122086552 |\n",
        "| [32, 256] | 32 | 50 | 0.4879702041143264 | 0.3517854687301486 |\n",
        "| [32, 256] | 64 | 60 | 0.47734473091428953 | 0.35245407907606846 |\n",
        "| [32, 256] | 128 | 80 | 0.47116296786118445 | 0.35266136512639207 |\n",
        "| [32, 256] | 256 | 130 | 0.49059173060902855 | 0.35291393811985433 |\n",
        "| [32, 256] | 512 | 160 | 0.45808960359670453 | 0.35097953315558644 |\n",
        "| [32, 512] | 32 | 50 | 0.5076814100559679 | 0.3521317795810667 |\n",
        "| [32, 512] | 64 | 50 | 0.4625676369439403 | 0.3542414364806836 |\n",
        "| [32, 512] | 128 | 70 | 0.46512525025000084 | 0.3527059014289503 |\n",
        "| [32, 512] | 256 | 90 | 0.4507865858215482 | 0.3523437141842701 |\n",
        "| [32, 512] | 512 | 140 | 0.4624769089335927 | 0.35345885559957096 |\n",
        "| [64, 32] | 32 | 50 | 0.5017733043285105 | 0.35872979444239467 |\n",
        "| [64, 32] | 64 | 70 | 0.5082508006545847 | 0.3600456375143 |\n",
        "| [64, 32] | 128 | 80 | 0.4818669121282903 | 0.3602922105788539 |\n",
        "| [64, 32] | 256 | 120 | 0.48945038015407494 | 0.3593044090521456 |\n",
        "| [64, 32] | 512 | 140 | 0.4519026977967834 | 0.35649467730619844 |\n",
        "| [64, 64] | 32 | 60 | 0.4999454526370554 | 0.36515000522865493 |\n",
        "| [64, 64] | 64 | 90 | 0.5288894659888791 | 0.36626392298706 |\n",
        "| [64, 64] | 128 | 110 | 0.5167730798544086 | 0.3664094297590882 |\n",
        "| [64, 64] | 256 | 120 | 0.47549464815809706 | 0.3651224997268548 |\n",
        "| [64, 64] | 512 | 210 | 0.5228911069973523 | **0.3688918486855366** |\n",
        "| [64, 128] | 32 | 50 | 0.5256763827090827 | 0.3436840438702426 |\n",
        "| [64, 128] | 64 | 50 | 0.47621071051056635 | 0.34935614980525853 |\n",
        "| [64, 128] | 128 | 70 | 0.492985054394737 | 0.3541966554711201 |\n",
        "| [64, 128] | 256 | 100 | 0.49597662265953607 | 0.35313526037712695 |\n",
        "| [64, 128] | 512 | 150 | 0.5069918503234064 | 0.3526837630207277 |\n",
        "| [64, 256] | 32 | 50 | 0.5494891168785351 | 0.35883686890825656 |\n",
        "| [64, 256] | 64 | 60 | 0.5269415293432682 | 0.36249765190193034 |\n",
        "| [64, 256] | 128 | 80 | 0.5300505203434721 | 0.3589246457736425 |\n",
        "| [64, 256] | 256 | 100 | 0.5080241887029228 | 0.36016269843549736 |\n",
        "| [64, 256] | 512 | 140 | 0.5059537522589852 | 0.3587068710399753 |\n",
        "| [64, 512] | 32 | 40 | 0.5401983496880267 | 0.35321207201271876 |\n",
        "| [64, 512] | 64 | 50 | 0.5318604001907415 | 0.36099390689766553 |\n",
        "| [64, 512] | 128 | 70 | 0.5421689778085229 | 0.36105933507373916 |\n",
        "| [64, 512] | 256 | 80 | 0.4944382209176507 | 0.3626388856407587 |\n",
        "| [64, 512] | 512 | 130 | 0.5196652036143773 | 0.36225251211290205 |\n",
        "| [128, 32] | 32 | 50 | 0.5249271832296621 | 0.35760718583215756 |\n",
        "| [128, 32] | 64 | 80 | 0.5685025740689781 | 0.36377939633090767 |\n",
        "| [128, 32] | 128 | 80 | 0.5139759118893513 | 0.3648175248658738 |\n",
        "| [128, 32] | 256 | 100 | 0.4952233549899021 | 0.3564903714865462 |\n",
        "| [128, 32] | 512 | 160 | 0.5147025480042984 | 0.36135181855850185 |\n",
        "| [128, 64] | 32 | 50 | 0.5738080318348487 | 0.36239898747388705 |\n",
        "| [128, 64] | 64 | 50 | 0.5196744338346704 | 0.356533390774149 |\n",
        "| [128, 64] | 128 | 70 | 0.5317510804320469 | 0.3572402072946805 |\n",
        "| [128, 64] | 256 | 80 | 0.48812725659154754 | 0.35517634016323213 |\n",
        "| [128, 64] | 512 | 120 | 0.4928091463886728 | 0.35535589307344057 |\n",
        "| [128, 128] | 32 | 30 | 0.5180119796291096 | 0.35591540698998897 |\n",
        "| [128, 128] | 64 | 40 | 0.5253773911651628 | 0.3574734787149585 |\n",
        "| [128, 128] | 128 | 60 | 0.5477979642672689 | 0.3590288563409101 |\n",
        "| [128, 128] | 256 | 70 | 0.5092802438075198 | 0.36074254358301516 |\n",
        "| [128, 128] | 512 | 120 | 0.5499484279862112 | 0.3588146512241456 |\n",
        "| [128, 256] | 32 | 30 | 0.5105203622305265 | 0.3587707117844619 |\n",
        "| [128, 256] | 64 | 60 | 0.5979701179675816 | 0.3483910760126731 |\n",
        "| [128, 256] | 128 | 60 | 0.5375379425989347 | 0.3571144401828996 |\n",
        "| [128, 256] | 256 | 80 | 0.5255759939044361 | 0.35982609689586265 |\n",
        "| [128, 256] | 512 | 110 | 0.5099185190234068 | 0.35963302396225366 |\n",
        "| [128, 512] | 32 | 40 | 0.6087175732336804 | 0.34509126397210504 |\n",
        "| [128, 512] | 64 | 40 | 0.5490352041120409 | 0.35840229732302004 |\n",
        "| [128, 512] | 128 | 60 | 0.5692428465652248 | 0.36039270279129104 |\n",
        "| [128, 512] | 256 | 80 | 0.5593548952789219 | 0.3578720909181322 |\n",
        "| [128, 512] | 512 | 100 | 0.5232604125350693 | 0.3589824505411314 |\n",
        "| [256, 32] | 32 | 50 | 0.6195472376576506 | 0.3557453465832519 |\n",
        "| [256, 32] | 64 | 50 | 0.5563804056392209 | 0.36367792457280357 |\n",
        "| [256, 32] | 128 | 60 | 0.5393136872926895 | 0.3610146053650587 |\n",
        "| [256, 32] | 256 | 80 | 0.5335812928400498 | 0.363278246196464 |\n",
        "| [256, 32] | 512 | 140 | 0.5734618054297648 | 0.3633220253579395 |\n",
        "| [256, 64] | 32 | 40 | 0.5461654804024745 | 0.3514624499793854 |\n",
        "| [256, 64] | 64 | 40 | 0.5014152491520321 | 0.35704700757568464 |\n",
        "| [256, 64] | 128 | 70 | 0.5685993638069473 | 0.3579603834979342 |\n",
        "| [256, 64] | 256 | 90 | 0.5532983304285045 | 0.3612728027167668 |\n",
        "| [256, 64] | 512 | 120 | 0.5397913602071595 | 0.3625542689527807 |\n",
        "| [256, 128] | 32 | 30 | 0.5751101278909201 | 0.35622548590492054 |\n",
        "| [256, 128] | 64 | 40 | 0.5808126596396925 | 0.3576858146716209 |\n",
        "| [256, 128] | 128 | 60 | 0.6107183590079956 | 0.36312025863448655 |\n",
        "| [256, 128] | 256 | 80 | 0.6002998835218126 | 0.36162464810100253 |\n",
        "| [256, 128] | 512 | 100 | 0.5563979841428376 | 0.3644687677651771 |\n",
        "| [256, 256] | 32 | 40 | 0.6291331839861412 | 0.3506029149198077 |\n",
        "| [256, 256] | 64 | 40 | 0.5695509042109238 | 0.3572348127585443 |\n",
        "| [256, 256] | 128 | 40 | 0.5090532832286437 | 0.36040476288879725 |\n",
        "| [256, 256] | 256 | 60 | 0.5204361648474637 | 0.3645906716991325 |\n",
        "| [256, 256] | 512 | 100 | 0.5615250273811208 | 0.3618892360575652 |\n",
        "| [256, 512] | 32 | 30 | 0.5907409393875985 | 0.3564003969888556 |\n",
        "| [256, 512] | 64 | 40 | 0.6067050252263743 | 0.3556896616542178 |\n",
        "| [256, 512] | 128 | 50 | 0.5954272195571649 | 0.3582021660717044 |\n",
        "| [256, 512] | 256 | 70 | 0.5976306911296411 | 0.35736860541759585 |\n",
        "| [256, 512] | 512 | 90 | 0.5705900509506002 | 0.3576595848614088 |\n",
        "| [512, 32] | 32 | 30 | 0.5419074818681398 | 0.36196331560976197 |\n",
        "| [512, 32] | 64 | 40 | 0.5508422389751494 | 0.3542479201862902 |\n",
        "| [512, 32] | 128 | 50 | 0.5491332492787844 | 0.3599954699406033 |\n",
        "| [512, 32] | 256 | 70 | 0.5477602713071558 | 0.3598743729389123 |\n",
        "| [512, 32] | 512 | 90 | 0.5207274821547373 | 0.36096356027225746 |\n",
        "| [512, 64] | 32 | 30 | 0.5618102403318733 | 0.3564562706132819 |\n",
        "| [512, 64] | 64 | 40 | 0.5828353571211595 | 0.3555416806816426 |\n",
        "| [512, 64] | 128 | 50 | 0.5723584849504204 | 0.3570558600224812 |\n",
        "| [512, 64] | 256 | 70 | 0.5862492012751988 | 0.3556519771525367 |\n",
        "| [512, 64] | 512 | 90 | 0.5576413872758721 | 0.3585821559465128 |\n",
        "| [512, 128] | 32 | 30 | 0.5812244600138176 | 0.3471274911395109 |\n",
        "| [512, 128] | 64 | 40 | 0.6106870282302498 | 0.3557103429810736 |\n",
        "| [512, 128] | 128 | 40 | 0.5501834512912124 | 0.36250493526584904 |\n",
        "| [512, 128] | 256 | 70 | 0.6187979699160502 | 0.3515848222457987 |\n",
        "| [512, 128] | 512 | 80 | 0.549300334035669 | 0.3563584770996534 |\n",
        "| [512, 256] | 32 | 30 | 0.6293914190652328 | 0.3506981350615361 |\n",
        "| [512, 256] | 64 | 30 | 0.5865646576172406 | 0.355044666676185 |\n",
        "| [512, 256] | 128 | 40 | 0.5922234856934344 | 0.3543297974235625 |\n",
        "| [512, 256] | 256 | 50 | 0.5732103080202352 | 0.3536901261250561 |\n",
        "| [512, 256] | 512 | 80 | 0.6074728435139047 | 0.36008120848473274 |\n",
        "| [512, 512] | 32 | 20 | 0.5646885592017371 | 0.3530281135406622 |\n",
        "| [512, 512] | 64 | 30 | 0.6114552447196876 | 0.3491200624617726 |\n",
        "| [512, 512] | 128 | 30 | 0.5498582854139467 | 0.35810458536940887 |\n",
        "| [512, 512] | 256 | 50 | 0.6017678539851714 | 0.3554978351483823 |\n",
        "| [512, 512] | 512 | 70 | 0.5903664204005237 | 0.36072800770364966 |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tenQAVu0HODq",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0.001\n",
        "\n",
        "\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| [32, 32] | 32 | 40 | 0.49220829899622603 | 0.35092664847688443 |\n",
        "| [32, 32] | 64 | 50 | 0.4814242237420692 | 0.35336728521759164 |\n",
        "| [32, 32] | 128 | 60 | 0.4623328591987379 | 0.35481357280737624 |\n",
        "| [32, 32] | 256 | 100 | 0.482055365879759 | 0.35386552652642705 |\n",
        "| [32, 32] | 512 | 120 | 0.45368229268398846 | 0.3548117063226977 |\n",
        "| [32, 64] | 32 | 30 | 0.46970603986050047 | 0.3464953631119434 |\n",
        "| [32, 64] | 64 | 50 | 0.5038283753937575 | 0.3470060639477771 |\n",
        "| [32, 64] | 128 | 50 | 0.45252451205433186 | 0.34808923194702457 |\n",
        "| [32, 64] | 256 | 80 | 0.4683281268716328 | 0.3456602235825528 |\n",
        "| [32, 64] | 512 | 100 | 0.4456185036973398 | 0.3460722868375535 |\n",
        "| [32, 128] | 32 | 30 | 0.4953499398255297 | 0.34413403184735825 |\n",
        "| [32, 128] | 64 | 40 | 0.4947972288941642 | 0.3413263285240755 |\n",
        "| [32, 128] | 128 | 50 | 0.4792860605329388 | 0.34806116532695974 |\n",
        "| [32, 128] | 256 | 70 | 0.47263481440104377 | 0.3492924112688629 |\n",
        "| [32, 128] | 512 | 90 | 0.4542999750522939 | 0.3511657741553443 |\n",
        "| [32, 256] | 32 | 30 | 0.5154147483830246 | 0.3500116616793944 |\n",
        "| [32, 256] | 64 | 40 | 0.5137122847842815 | 0.34964711606728 |\n",
        "| [32, 256] | 128 | 50 | 0.5015494438727124 | 0.3489774500246439 |\n",
        "| [32, 256] | 256 | 70 | 0.49118554924565666 | 0.35263849491641047 |\n",
        "| [32, 256] | 512 | 100 | 0.4806364035907918 | 0.3535470748567105 |\n",
        "| [32, 512] | 32 | 20 | 0.4899783924771183 | 0.33251553841525444 |\n",
        "| [32, 512] | 64 | 30 | 0.5030222264397366 | 0.3282021573221569 |\n",
        "| [32, 512] | 128 | 40 | 0.48568620480059965 | 0.3400918083674615 |\n",
        "| [32, 512] | 256 | 50 | 0.4601295939510631 | 0.3444868489755288 |\n",
        "| [32, 512] | 512 | 70 | 0.45618263488675787 | 0.34464840817562464 |\n",
        "| [64, 32] | 32 | 30 | 0.5290327464336355 | 0.34605905936722636 |\n",
        "| [64, 32] | 64 | 40 | 0.5182915939129374 | 0.35046352087961224 |\n",
        "| [64, 32] | 128 | 50 | 0.5050843654030664 | 0.35073774823884163 |\n",
        "| [64, 32] | 256 | 70 | 0.49857955862397163 | 0.34960669830376256 |\n",
        "| [64, 32] | 512 | 100 | 0.4953961234223967 | 0.35419207760715293 |\n",
        "| [64, 64] | 32 | 30 | 0.5321059797841452 | 0.35547005530468156 |\n",
        "| [64, 64] | 64 | 40 | 0.5284725730513365 | 0.35404423423542636 |\n",
        "| [64, 64] | 128 | 50 | 0.5048643945562385 | 0.358154874791565 |\n",
        "| [64, 64] | 256 | 70 | 0.49787378262584414 | 0.36029881588153717 |\n",
        "| [64, 64] | 512 | 90 | 0.47286944789678603 | **0.36298889594266526** |\n",
        "| [64, 128] | 32 | 30 | 0.5849697371780138 | 0.3376878616818794 |\n",
        "| [64, 128] | 64 | 30 | 0.523408372075128 | 0.35156295476869703 |\n",
        "| [64, 128] | 128 | 40 | 0.5170019344951011 | 0.3500527626734647 |\n",
        "| [64, 128] | 256 | 50 | 0.49076980473963105 | 0.3510334547570223 |\n",
        "| [64, 128] | 512 | 70 | 0.4842119321957344 | 0.35209782009341606 |\n",
        "| [64, 256] | 32 | 30 | 0.5760793991752905 | 0.34452705640663517 |\n",
        "| [64, 256] | 64 | 30 | 0.5247109534565682 | 0.35333280221079816 |\n",
        "| [64, 256] | 128 | 40 | 0.5197438836500577 | 0.3519232860652139 |\n",
        "| [64, 256] | 256 | 50 | 0.4968100124543012 | 0.3570168121520941 |\n",
        "| [64, 256] | 512 | 70 | 0.48983288608978964 | 0.35522034837044697 |\n",
        "| [64, 512] | 32 | 20 | 0.5499122951333788 | 0.3357365033779437 |\n",
        "| [64, 512] | 64 | 30 | 0.5696225814471075 | 0.3289441979020294 |\n",
        "| [64, 512] | 128 | 30 | 0.508183132914768 | 0.34696702320618816 |\n",
        "| [64, 512] | 256 | 40 | 0.4905154730174879 | 0.3489190869677597 |\n",
        "| [64, 512] | 512 | 60 | 0.49505689936540503 | 0.34690359118534525 |\n",
        "| [128, 32] | 32 | 30 | 0.5938475535687953 | 0.3485381212752656 |\n",
        "| [128, 32] | 64 | 40 | 0.5903090587785399 | 0.3517772231106364 |\n",
        "| [128, 32] | 128 | 50 | 0.5735979655201162 | 0.34789932880035207 |\n",
        "| [128, 32] | 256 | 70 | 0.5678678191746906 | 0.3501491228491053 |\n",
        "| [128, 32] | 512 | 100 | 0.5632691108254277 | 0.35057831983657595 |\n",
        "| [128, 64] | 32 | 20 | 0.5478902855067767 | 0.3388997395245118 |\n",
        "| [128, 64] | 64 | 30 | 0.5735098273523843 | 0.33923056102149035 |\n",
        "| [128, 64] | 128 | 40 | 0.5616435416161261 | 0.3445626224582357 |\n",
        "| [128, 64] | 256 | 50 | 0.5304185912115482 | 0.351796889344657 |\n",
        "| [128, 64] | 512 | 70 | 0.5199774552048672 | 0.3546881384160965 |\n",
        "| [128, 128] | 32 | 20 | 0.5874930888107026 | 0.33997881213258596 |\n",
        "| [128, 128] | 64 | 30 | 0.6112999933747997 | 0.33453939705729663 |\n",
        "| [128, 128] | 128 | 30 | 0.539633970929768 | 0.34941903605026153 |\n",
        "| [128, 128] | 256 | 40 | 0.517999772562526 | 0.35354188255091884 |\n",
        "| [128, 128] | 512 | 60 | 0.5287819260513144 | 0.35165268215658513 |\n",
        "| [128, 256] | 32 | 20 | 0.6091529901556677 | 0.3306415455622169 |\n",
        "| [128, 256] | 64 | 20 | 0.5402706432932518 | 0.3419752371965145 |\n",
        "| [128, 256] | 128 | 30 | 0.5552441643062992 | 0.3366510548731301 |\n",
        "| [128, 256] | 256 | 40 | 0.5368663593034899 | 0.34442229905038785 |\n",
        "| [128, 256] | 512 | 50 | 0.4985317306133952 | 0.34930500306054935 |\n",
        "| [128, 512] | 32 | 20 | 0.6386974606845096 | 0.32422169378605586 |\n",
        "| [128, 512] | 64 | 20 | 0.5700352681804732 | 0.34042993050294845 |\n",
        "| [128, 512] | 128 | 30 | 0.590284266220035 | 0.3452747812983865 |\n",
        "| [128, 512] | 256 | 40 | 0.5647640831349545 | 0.3521847830492433 |\n",
        "| [128, 512] | 512 | 50 | 0.5262224463127279 | 0.35286066214579265 |\n",
        "| [256, 32] | 32 | 20 | 0.5968803709145881 | 0.3536098532589031 |\n",
        "| [256, 32] | 64 | 30 | 0.6278749308232062 | 0.3537787449596557 |\n",
        "| [256, 32] | 128 | 40 | 0.6233092332777945 | 0.3562697194398134 |\n",
        "| [256, 32] | 256 | 50 | 0.5920866234844513 | 0.35414694313192724 |\n",
        "| [256, 32] | 512 | 70 | 0.5799499721085484 | 0.3571348064759131 |\n",
        "| [256, 64] | 32 | 20 | 0.6300591609181392 | 0.34987408296108075 |\n",
        "| [256, 64] | 64 | 30 | 0.6551040742691451 | 0.3442128183735948 |\n",
        "| [256, 64] | 128 | 30 | 0.5747788209351343 | 0.3603645835260601 |\n",
        "| [256, 64] | 256 | 40 | 0.5481061640217578 | 0.36095926865265526 |\n",
        "| [256, 64] | 512 | 60 | 0.5590083704496889 | 0.3616885754411477 |\n",
        "| [256, 128] | 32 | 20 | 0.6966667066745962 | 0.32754671592942164 |\n",
        "| [256, 128] | 64 | 20 | 0.6067113168138177 | 0.34352184795938756 |\n",
        "| [256, 128] | 128 | 30 | 0.6338465784152287 | 0.3351081999844846 |\n",
        "| [256, 128] | 256 | 40 | 0.6121486143571581 | 0.3446088140511725 |\n",
        "| [256, 128] | 512 | 50 | 0.5634122316012783 | 0.3539056753699886 |\n",
        "| [256, 256] | 32 | 20 | 0.7255063078806151 | 0.3191919452436102 |\n",
        "| [256, 256] | 64 | 20 | 0.6331412202718765 | 0.3394758163869767 |\n",
        "| [256, 256] | 128 | 30 | 0.6712839529303881 | 0.33389214980261506 |\n",
        "| [256, 256] | 256 | 30 | 0.5540993893818433 | 0.351866096767011 |\n",
        "| [256, 256] | 512 | 50 | 0.5935589399428641 | 0.34611086832794663 |\n",
        "| [256, 512] | 32 | 20 | 0.7667756411383152 | 0.28951877056564734 |\n",
        "| [256, 512] | 64 | 20 | 0.6723740383135323 | 0.3231751521695537 |\n",
        "| [256, 512] | 128 | 20 | 0.5835852779358826 | 0.34141275392319975 |\n",
        "| [256, 512] | 256 | 30 | 0.589538591181283 | 0.3395809766998332 |\n",
        "| [256, 512] | 512 | 40 | 0.5600888716127227 | 0.348120032840422 |\n",
        "| [512, 32] | 32 | 20 | 0.724972855458449 | 0.3331882021343027 |\n",
        "| [512, 32] | 64 | 20 | 0.6290953279435735 | 0.35320821518874235 |\n",
        "| [512, 32] | 128 | 30 | 0.6578192164077843 | 0.3524640437088937 |\n",
        "| [512, 32] | 256 | 40 | 0.633450302530175 | 0.3549363667600653 |\n",
        "| [512, 32] | 512 | 50 | 0.5802491756886101 | 0.3621849431968058 |\n",
        "| [512, 64] | 32 | 20 | 0.760050790762964 | 0.3258258091224857 |\n",
        "| [512, 64] | 64 | 20 | 0.664849173125861 | 0.3368138381066152 |\n",
        "| [512, 64] | 128 | 30 | 0.6985525721730933 | 0.3323136912577013 |\n",
        "| [512, 64] | 256 | 30 | 0.5830843282883214 | 0.3495385625985171 |\n",
        "| [512, 64] | 512 | 40 | 0.5525641062363739 | 0.35032644015852515 |\n",
        "| [512, 128] | 32 | 20 | 0.8035276579904501 | 0.30421017152988805 |\n",
        "| [512, 128] | 64 | 20 | 0.7077495836273445 | 0.3306045319715496 |\n",
        "| [512, 128] | 128 | 20 | 0.6076135253060287 | 0.34387969258578266 |\n",
        "| [512, 128] | 256 | 30 | 0.6239506935317523 | 0.34745580098039736 |\n",
        "| [512, 128] | 512 | 40 | 0.5929474225987593 | 0.3474017983968875 |\n",
        "| [512, 256] | 32 | 20 | 0.8629656049246619 | 0.27932241879825775 |\n",
        "| [512, 256] | 64 | 20 | 0.7757517901360209 | 0.30086575690165407 |\n",
        "| [512, 256] | 128 | 20 | 0.6550498778702409 | 0.3371205237782683 |\n",
        "| [512, 256] | 256 | 30 | 0.6763416074242495 | 0.33425606157790966 |\n",
        "| [512, 256] | 512 | 30 | 0.5533762703123488 | 0.35313271179873107 |\n",
        "| [512, 512] | 32 | 20 | 0.887546556023914 | 0.2543909206381692 |\n",
        "| [512, 512] | 64 | 20 | 0.8027367334752653 | 0.2935067540314058 |\n",
        "| [512, 512] | 128 | 20 | 0.6972190916364553 | 0.31879209461900665 |\n",
        "| [512, 512] | 256 | 30 | 0.7095946775338411 | 0.3246259588251714 |\n",
        "| [512, 512] | 512 | 30 | 0.5796865137498517 | 0.34465830068644226 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zymVrozZ8rYN",
        "colab_type": "text"
      },
      "source": [
        "##### Weight Decay = 0.0001\n",
        "\n",
        "\n",
        "\n",
        "| Hidden Sizes | Batch Size | Final Epoch | Training Pearson Score | Validation Pearson Score |\n",
        "|---|---|---|---|---|\n",
        "| [32, 32] | 32 | 40 | 0.505823422288478 | 0.35208704782400835 |\n",
        "| [32, 32] | 64 | 50 | 0.49037698762052784 | 0.3518732695797378 |\n",
        "| [32, 32] | 128 | 60 | 0.470264244455386 | 0.3521522512598751 |\n",
        "| [32, 32] | 256 | 80 | 0.4592030937751869 | 0.3525995328811597 |\n",
        "| [32, 32] | 512 | 120 | 0.4630796156424533 | 0.35408842483464453 |\n",
        "| [32, 64] | 32 | 30 | 0.47709959975912886 | 0.3487666771085576 |\n",
        "| [32, 64] | 64 | 40 | 0.4752297883881018 | 0.35049327884776027 |\n",
        "| [32, 64] | 128 | 60 | 0.4879883541884056 | 0.35114715253843126 |\n",
        "| [32, 64] | 256 | 70 | 0.45569665492945394 | 0.34818244420907407 |\n",
        "| [32, 64] | 512 | 100 | 0.4554815156572567 | 0.3470677014110536 |\n",
        "| [32, 128] | 32 | 30 | 0.5014691207632432 | 0.3419827451680263 |\n",
        "| [32, 128] | 64 | 40 | 0.4949133688062435 | 0.3378985771953629 |\n",
        "| [32, 128] | 128 | 40 | 0.4589822981030443 | 0.34776470134502113 |\n",
        "| [32, 128] | 256 | 60 | 0.4611340980141366 | 0.34707911882342335 |\n",
        "| [32, 128] | 512 | 90 | 0.46329305222778044 | 0.3463444973224244 |\n",
        "| [32, 256] | 32 | 30 | 0.5285825236050112 | 0.34715347906720057 |\n",
        "| [32, 256] | 64 | 30 | 0.48400379781324576 | 0.3569206194454497 |\n",
        "| [32, 256] | 128 | 40 | 0.47660329005023033 | 0.35543008908011187 |\n",
        "| [32, 256] | 256 | 60 | 0.48061403986874496 | 0.35310393310741733 |\n",
        "| [32, 256] | 512 | 80 | 0.46383492480735516 | 0.35260414686113595 |\n",
        "| [32, 512] | 32 | 20 | 0.5017216794418631 | 0.3234148204139296 |\n",
        "| [32, 512] | 64 | 30 | 0.5170884655707663 | 0.3190219832875727 |\n",
        "| [32, 512] | 128 | 40 | 0.5092333244831441 | 0.324760617247735 |\n",
        "| [32, 512] | 256 | 50 | 0.48458488154870993 | 0.32990910140845187 |\n",
        "| [32, 512] | 512 | 60 | 0.45695857130165946 | 0.33466880065703186 |\n",
        "| [64, 32] | 32 | 30 | 0.5378038673854566 | 0.34321315927271673 |\n",
        "| [64, 32] | 64 | 40 | 0.5280764677738512 | 0.34520544682154486 |\n",
        "| [64, 32] | 128 | 50 | 0.5143859485372471 | 0.34680882767087834 |\n",
        "| [64, 32] | 256 | 60 | 0.4822791433762219 | 0.34945289402224206 |\n",
        "| [64, 32] | 512 | 80 | 0.4692163868413653 | 0.3509332187376666 |\n",
        "| [64, 64] | 32 | 30 | 0.5436982980817271 | 0.3431338406224313 |\n",
        "| [64, 64] | 64 | 40 | 0.5339999811709546 | 0.3519879363889759 |\n",
        "| [64, 64] | 128 | 50 | 0.5149696707764282 | 0.3549081252467525 |\n",
        "| [64, 64] | 256 | 60 | 0.48188652386026043 | 0.35923471844303356 |\n",
        "| [64, 64] | 512 | 90 | 0.4871774318230596 | **0.36183749626325623** |\n",
        "| [64, 128] | 32 | 20 | 0.5243103131735792 | 0.3455945671763587 |\n",
        "| [64, 128] | 64 | 30 | 0.5346341781338338 | 0.3436971162953363 |\n",
        "| [64, 128] | 128 | 40 | 0.5284548595250704 | 0.3446523690665402 |\n",
        "| [64, 128] | 256 | 50 | 0.5021094530552034 | 0.3462620745361478 |\n",
        "| [64, 128] | 512 | 70 | 0.5002772332530007 | 0.34718163621904746 |\n",
        "| [64, 256] | 32 | 30 | 0.5929278814458947 | 0.3394668484428862 |\n",
        "| [64, 256] | 64 | 30 | 0.535846710060695 | 0.3507148278797935 |\n",
        "| [64, 256] | 128 | 40 | 0.5350204736291667 | 0.3457623304760307 |\n",
        "| [64, 256] | 256 | 50 | 0.5094068574318379 | 0.35025242085051933 |\n",
        "| [64, 256] | 512 | 70 | 0.5065187444431162 | 0.3543220305945619 |\n",
        "| [64, 512] | 32 | 20 | 0.5595211165049472 | 0.32981630754678 |\n",
        "| [64, 512] | 64 | 30 | 0.5834017053607854 | 0.3139179290484565 |\n",
        "| [64, 512] | 128 | 30 | 0.5238281858468297 | 0.34077616381414644 |\n",
        "| [64, 512] | 256 | 40 | 0.5080456320927217 | 0.34481656429461244 |\n",
        "| [64, 512] | 512 | 50 | 0.48191985814141547 | 0.35232497637352694 |\n",
        "| [128, 32] | 32 | 30 | 0.6044275215821936 | 0.3399519333804215 |\n",
        "| [128, 32] | 64 | 40 | 0.5997000720634801 | 0.3406443143505809 |\n",
        "| [128, 32] | 128 | 50 | 0.5829624394096283 | 0.3383670620542998 |\n",
        "| [128, 32] | 256 | 60 | 0.5405331625738093 | 0.3438474835792038 |\n",
        "| [128, 32] | 512 | 90 | 0.5481624258120793 | 0.3446329544838711 |\n",
        "| [128, 64] | 32 | 20 | 0.5556817407754253 | 0.33618165147655726 |\n",
        "| [128, 64] | 64 | 30 | 0.5801433100392112 | 0.33273598840422564 |\n",
        "| [128, 64] | 128 | 30 | 0.5078993628051661 | 0.34571555410261684 |\n",
        "| [128, 64] | 256 | 50 | 0.5391542890050969 | 0.34325174249332846 |\n",
        "| [128, 64] | 512 | 60 | 0.498659265686346 | 0.3495958844519912 |\n",
        "| [128, 128] | 32 | 20 | 0.6001861859642373 | 0.3368470765369504 |\n",
        "| [128, 128] | 64 | 30 | 0.624043189387397 | 0.3313504087841685 |\n",
        "| [128, 128] | 128 | 30 | 0.5475175866017413 | 0.34400055129757573 |\n",
        "| [128, 128] | 256 | 40 | 0.5293474984155755 | 0.3513873473385241 |\n",
        "| [128, 128] | 512 | 60 | 0.5421546959775038 | 0.3494712335975795 |\n",
        "| [128, 256] | 32 | 20 | 0.6151176142804811 | 0.3251729306628442 |\n",
        "| [128, 256] | 64 | 20 | 0.5491104008118843 | 0.3400793673387446 |\n",
        "| [128, 256] | 128 | 30 | 0.5672375124967568 | 0.33468287465104046 |\n",
        "| [128, 256] | 256 | 40 | 0.5504070160997051 | 0.34082059111788776 |\n",
        "| [128, 256] | 512 | 50 | 0.517177591108635 | 0.3454033249030222 |\n",
        "| [128, 512] | 32 | 20 | 0.6517414917381634 | 0.3183286374878705 |\n",
        "| [128, 512] | 64 | 20 | 0.580639127025956 | 0.32650362023209517 |\n",
        "| [128, 512] | 128 | 30 | 0.601829808285818 | 0.335544632487819 |\n",
        "| [128, 512] | 256 | 40 | 0.5794158134166872 | 0.3396870438533251 |\n",
        "| [128, 512] | 512 | 50 | 0.5478086681364609 | 0.3457338496297844 |\n",
        "| [256, 32] | 32 | 20 | 0.6197104444753478 | 0.3457144986438508 |\n",
        "| [256, 32] | 64 | 30 | 0.6479059767131523 | 0.34410697675324825 |\n",
        "| [256, 32] | 128 | 40 | 0.6384299078439426 | 0.35142831228043114 |\n",
        "| [256, 32] | 256 | 50 | 0.6065169461964632 | 0.3513422641505353 |\n",
        "| [256, 32] | 512 | 60 | 0.5514046360549553 | 0.35899293053904735 |\n",
        "| [256, 64] | 32 | 20 | 0.6469998813323583 | 0.339130371223262 |\n",
        "| [256, 64] | 64 | 20 | 0.5691579735056576 | 0.3534750219601805 |\n",
        "| [256, 64] | 128 | 30 | 0.5881508686069298 | 0.35202843809757633 |\n",
        "| [256, 64] | 256 | 40 | 0.5615996261288695 | 0.354230696573085 |\n",
        "| [256, 64] | 512 | 50 | 0.5252788338517802 | 0.35990926277337176 |\n",
        "| [256, 128] | 32 | 20 | 0.7113982433313375 | 0.3279882677784439 |\n",
        "| [256, 128] | 64 | 20 | 0.6223169795241147 | 0.34297085467706845 |\n",
        "| [256, 128] | 128 | 30 | 0.6491941516330276 | 0.33177493082814763 |\n",
        "| [256, 128] | 256 | 40 | 0.62604762689492 | 0.3411842514899606 |\n",
        "| [256, 128] | 512 | 50 | 0.5780201059615827 | 0.3500117003196546 |\n",
        "| [256, 256] | 32 | 20 | 0.7424329893375285 | 0.31506377945604574 |\n",
        "| [256, 256] | 64 | 20 | 0.649250723005728 | 0.3305695927538402 |\n",
        "| [256, 256] | 128 | 30 | 0.6852883806076323 | 0.3219414669690295 |\n",
        "| [256, 256] | 256 | 30 | 0.5724555604125487 | 0.34732668237950215 |\n",
        "| [256, 256] | 512 | 40 | 0.5483990312076282 | 0.34773191770685885 |\n",
        "| [256, 512] | 32 | 20 | 0.7824189213621108 | 0.279793776364684 |\n",
        "| [256, 512] | 64 | 20 | 0.6896720593389389 | 0.3101808975229983 |\n",
        "| [256, 512] | 128 | 20 | 0.60338926650279 | 0.3356336502917889 |\n",
        "| [256, 512] | 256 | 30 | 0.6097007683116058 | 0.3326968722130576 |\n",
        "| [256, 512] | 512 | 40 | 0.587149730240542 | 0.33950993423713 |\n",
        "| [512, 32] | 32 | 20 | 0.7461743042275069 | 0.321446278168305 |\n",
        "| [512, 32] | 64 | 20 | 0.644913366212597 | 0.3483031615777772 |\n",
        "| [512, 32] | 128 | 30 | 0.6724302084444705 | 0.34533608780189556 |\n",
        "| [512, 32] | 256 | 40 | 0.6477513266681929 | 0.352426726791974 |\n",
        "| [512, 32] | 512 | 50 | 0.5935091284770635 | 0.35900178315333175 |\n",
        "| [512, 64] | 32 | 20 | 0.7820541398530194 | 0.3166445748926883 |\n",
        "| [512, 64] | 64 | 20 | 0.6818484009843438 | 0.32909293533898454 |\n",
        "| [512, 64] | 128 | 30 | 0.7149314461115528 | 0.33076436041895546 |\n",
        "| [512, 64] | 256 | 30 | 0.5962775215284128 | 0.3492206727353766 |\n",
        "| [512, 64] | 512 | 40 | 0.5676347891241046 | 0.3508315956025261 |\n",
        "| [512, 128] | 32 | 20 | 0.8229149134376538 | 0.3001021965171695 |\n",
        "| [512, 128] | 64 | 20 | 0.7267707987734563 | 0.32392133197165146 |\n",
        "| [512, 128] | 128 | 20 | 0.624037726777915 | 0.342007016836002 |\n",
        "| [512, 128] | 256 | 30 | 0.6413814614930899 | 0.3446103049980825 |\n",
        "| [512, 128] | 512 | 40 | 0.6138212565348751 | 0.3426753157705122 |\n",
        "| [512, 256] | 32 | 20 | 0.879604461892583 | 0.25754215369093464 |\n",
        "| [512, 256] | 64 | 20 | 0.7908816543354489 | 0.2827369562956576 |\n",
        "| [512, 256] | 128 | 20 | 0.6747287650493594 | 0.32346635099623494 |\n",
        "| [512, 256] | 256 | 30 | 0.6949852212846929 | 0.3155644450786335 |\n",
        "| [512, 256] | 512 | 30 | 0.5723789201320868 | 0.3444996081916982 |\n",
        "| [512, 512] | 32 | 20 | 0.8996420723531632 | 0.23109622597671117 |\n",
        "| [512, 512] | 64 | 20 | 0.8183769336481277 | 0.26663308474633246 |\n",
        "| [512, 512] | 128 | 20 | 0.7161010860517311 | 0.30606238277378073 |\n",
        "| [512, 512] | 256 | 20 | 0.5947669945351728 | 0.34053336811274176 |\n",
        "| [512, 512] | 512 | 30 | 0.6081618050928611 | 0.3376470592289059 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_eVxCFdo8kJ",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XimIq82so7Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def writeScores(scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")\n",
        "\n",
        "\n",
        "def downloadScores(method_name, scores):\n",
        "  writeScores(scores)\n",
        "  with ZipFile(f\"en-zh_{method_name}.zip\", \"w\") as newzip:\n",
        "    newzip.write(\"predictions.txt\")\n",
        "  \n",
        "  files.download(f\"en-zh_{method_name}.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqqn82FwD9xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}